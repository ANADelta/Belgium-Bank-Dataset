{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Belgium Bank Dataset Cleaning and Preparation Pipeline\n",
    "\n",
    "## ğŸ“Š Project Overview\n",
    "\n",
    "This notebook contains a professional data cleaning and preparation pipeline for the **Belgium Bank Dataset**, with the goal of transforming raw bank customer data into a structured, consistent, and analysis-ready format. The steps are fully documented for transparency and reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”‘ Objectives:\n",
    "- Load and inspect the raw dataset.\n",
    "- Rename and translate columns to English.\n",
    "- Detect and handle missing or invalid values.\n",
    "- Standardize and normalize formats (e.g., IBAN, birth dates).\n",
    "- Create a clean output dataset ready for analysis or machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Code Block 1: Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Optional: For regular expressions (Pandas uses regex internally but can import if needed)\n",
    "import re\n",
    "\n",
    "\n",
    "# âš™ï¸ Configuration for visualization\n",
    "pd.set_option('display.max_columns', None)  # Show all columns in output\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "print(\"âœ… Libraries imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Step 1: Dataset Loading with Encoding Handling\n",
    "\n",
    "In this step:\n",
    "- We attempt to load the raw Belgium Bank dataset.\n",
    "- Since datasets from Europe may contain special characters, we handle potential encoding issues.\n",
    "- First, we try UTF-8 (standard), but if that fails, we fallback to Latin-1 encoding.\n",
    "\n",
    "Below, we also preview the first 5 rows to confirm that data is loaded properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ UTF-8 failed. Dataset loaded successfully using Latin-1 encoding.\n",
      "\n",
      "ğŸ” Preview of first 5 rows:\n",
      "  geslacht   achternaam voorletter tussenvoegsel                straatnaam  \\\n",
      "0      Dhr       Jacobs         C.           NaN              Gasmeterlaan   \n",
      "1      NaN        Dries         K.       van den              Groningenlei   \n",
      "2        M    Vermeulen       KURT           NaN            Schongaustraat   \n",
      "3        V     Oirschot         L.           van            Ertbrandstraat   \n",
      "4     Mevr  Compernolle         R.           NaN  Albrecht rodenbachstraat   \n",
      "\n",
      "  huisnummer toevoeging postcode            woonplaats  telefoonnummer  \\\n",
      "0        247        NaN     9000                  Gent     475644230.0   \n",
      "1         15        NaN     2550               Kontich      32899040.0   \n",
      "2          7        NaN     9100          Sint-niklaas      32966602.0   \n",
      "3        187      bus 1     2950  Kapellen (antwerpen)      36052791.0   \n",
      "4          4        NaN     8730               Beernem      50781034.0   \n",
      "\n",
      "  geboortedatum    rekeningnummer                 iban  \\\n",
      "0    24-12-1966    1462596514      BE94 0014 6259 6514   \n",
      "1    06/09/1987  860111889579      BE58 8601 1188 9579   \n",
      "2    13-08-1965  737015498825      BE70 7370 1549 8825   \n",
      "3    25-02-1950  733156017254      BE42 7331 5601 7254   \n",
      "4    04/08/1951   63461819055      BE31 0634 6181 9055   \n",
      "\n",
      "                              email         bic  \n",
      "0  christian22christian@hotmail.com  GEBA BE BB  \n",
      "1       k_van_den_dries@hotmail.com         NaN  \n",
      "2         kurt.vermeulen1@skynet.be         NaN  \n",
      "3             gido.imbert@skynet.be  KRED BE BB  \n",
      "4    rechina.compernolle@telenet.be  GKCC BE BB  \n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¥ Load dataset from raw_data folder with proper encoding handling\n",
    "file_path = '../raw_data/Belgium-Iban.csv'  # Adjust path if necessary\n",
    "\n",
    "# Attempt to read with utf-8, if it fails, fallback to 'latin-1'\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    print(\"âœ… Dataset loaded successfully with UTF-8 encoding.\")\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(file_path, encoding='latin-1')\n",
    "    print(\"âš ï¸ UTF-8 failed. Dataset loaded successfully using Latin-1 encoding.\")\n",
    "\n",
    "# ğŸ§ Preview first few rows to confirm data load\n",
    "print(\"\\nğŸ” Preview of first 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ·ï¸ Step 2: Rename Columns to English\n",
    "\n",
    "To ensure our dataset is globally accessible and easily understandable by international stakeholders, we translate all column names from Dutch to English.\n",
    "\n",
    "### Renamed Columns:\n",
    "- gender\n",
    "- last_name\n",
    "- initials\n",
    "- infix\n",
    "- street_name\n",
    "- house_number\n",
    "- addition\n",
    "- postal_code\n",
    "- city\n",
    "- phone_number\n",
    "- date_of_birth\n",
    "- account_number\n",
    "- iban\n",
    "- email\n",
    "- bic\n",
    "\n",
    "Below is the preview of the renamed dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Columns after renaming to English:\n",
      "['gender', 'last_name', 'initials', 'infix', 'street_name', 'house_number', 'addition', 'postal_code', 'city', 'phone_number', 'date_of_birth', 'account_number', 'iban', 'email', 'bic']\n",
      "\n",
      "ğŸ” Preview of data after renaming columns:\n",
      "  gender    last_name initials    infix               street_name  \\\n",
      "0    Dhr       Jacobs       C.      NaN              Gasmeterlaan   \n",
      "1    NaN        Dries       K.  van den              Groningenlei   \n",
      "2      M    Vermeulen     KURT      NaN            Schongaustraat   \n",
      "3      V     Oirschot       L.      van            Ertbrandstraat   \n",
      "4   Mevr  Compernolle       R.      NaN  Albrecht rodenbachstraat   \n",
      "\n",
      "  house_number addition postal_code                  city  phone_number  \\\n",
      "0          247      NaN        9000                  Gent   475644230.0   \n",
      "1           15      NaN        2550               Kontich    32899040.0   \n",
      "2            7      NaN        9100          Sint-niklaas    32966602.0   \n",
      "3          187    bus 1        2950  Kapellen (antwerpen)    36052791.0   \n",
      "4            4      NaN        8730               Beernem    50781034.0   \n",
      "\n",
      "  date_of_birth    account_number                 iban  \\\n",
      "0    24-12-1966    1462596514      BE94 0014 6259 6514   \n",
      "1    06/09/1987  860111889579      BE58 8601 1188 9579   \n",
      "2    13-08-1965  737015498825      BE70 7370 1549 8825   \n",
      "3    25-02-1950  733156017254      BE42 7331 5601 7254   \n",
      "4    04/08/1951   63461819055      BE31 0634 6181 9055   \n",
      "\n",
      "                              email         bic  \n",
      "0  christian22christian@hotmail.com  GEBA BE BB  \n",
      "1       k_van_den_dries@hotmail.com         NaN  \n",
      "2         kurt.vermeulen1@skynet.be         NaN  \n",
      "3             gido.imbert@skynet.be  KRED BE BB  \n",
      "4    rechina.compernolle@telenet.be  GKCC BE BB  \n"
     ]
    }
   ],
   "source": [
    "# ğŸ·ï¸ Step 2: Renaming Columns to English and Standardized Format\n",
    "\n",
    "# Mapping of Dutch to English column names\n",
    "column_rename_map = {\n",
    "    'geslacht': 'gender',\n",
    "    'achternaam': 'last_name',\n",
    "    'voorletter': 'initials',\n",
    "    'tussenvoegsel': 'infix',\n",
    "    'straatnaam': 'street_name',\n",
    "    'huisnummer': 'house_number',\n",
    "    'toevoeging': 'addition',\n",
    "    'postcode': 'postal_code',\n",
    "    'woonplaats': 'city',\n",
    "    'telefoonnummer': 'phone_number',\n",
    "    'geboortedatum': 'date_of_birth',\n",
    "    'rekeningnummer': 'account_number',\n",
    "    'iban': 'iban',\n",
    "    'email': 'email',\n",
    "    'bic': 'bic'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "df.rename(columns=column_rename_map, inplace=True)\n",
    "\n",
    "# âœ… Print renamed columns to verify\n",
    "print(\"\\nâœ… Columns after renaming to English:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# ğŸ” Show first 5 rows to confirm changes\n",
    "print(\"\\nğŸ” Preview of data after renaming columns:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 3: Data Types Standardization & Initial Cleaning\n",
    "ğŸ¯ Goal for this Step:\n",
    "Convert columns to proper data types (numbers, dates).\n",
    "Standardize formats (remove spaces, fix IBAN, phone numbers).\n",
    "Prepare data for deeper analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Code Block with Print Statements and Explanations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Starting data type standardization and cleaning process...\n",
      "\n",
      "ğŸ”¹ Converted 'house_number' to string.\n",
      "ğŸ”¹ Converted 'phone_number' and 'account_number' to string and cleaned decimals.\n",
      "ğŸ”¹ Cleaned IBAN numbers by removing spaces.\n",
      "ğŸ”¹ Converted 'date_of_birth' to datetime format (NaT if invalid).\n",
      "ğŸ”¹ Converted 'postal_code' to string and stripped whitespace.\n",
      "ğŸ”¹ Stripped whitespace from all text columns.\n",
      "\n",
      "ğŸ” Data types after standardization:\n",
      " gender                    object\n",
      "last_name                 object\n",
      "initials                  object\n",
      "infix                     object\n",
      "street_name               object\n",
      "house_number              object\n",
      "addition                  object\n",
      "postal_code               object\n",
      "city                      object\n",
      "phone_number              object\n",
      "date_of_birth     datetime64[ns]\n",
      "account_number            object\n",
      "iban                      object\n",
      "email                     object\n",
      "bic                       object\n",
      "dtype: object\n",
      "\n",
      "ğŸ” Preview of cleaned data:\n",
      "   gender    last_name initials    infix               street_name  \\\n",
      "0    Dhr       Jacobs       C.      NaN              Gasmeterlaan   \n",
      "1    NaN        Dries       K.  van den              Groningenlei   \n",
      "2      M    Vermeulen     KURT      NaN            Schongaustraat   \n",
      "3      V     Oirschot       L.      van            Ertbrandstraat   \n",
      "4   Mevr  Compernolle       R.      NaN  Albrecht rodenbachstraat   \n",
      "\n",
      "  house_number addition postal_code                  city phone_number  \\\n",
      "0          247      NaN        9000                  Gent    475644230   \n",
      "1           15      NaN        2550               Kontich     32899040   \n",
      "2            7      NaN        9100          Sint-niklaas     32966602   \n",
      "3          187    bus 1        2950  Kapellen (antwerpen)     36052791   \n",
      "4            4      NaN        8730               Beernem     50781034   \n",
      "\n",
      "  date_of_birth    account_number              iban  \\\n",
      "0    1966-12-24    1462596514      BE94001462596514   \n",
      "1           NaT  860111889579      BE58860111889579   \n",
      "2    1965-08-13  737015498825      BE70737015498825   \n",
      "3    1950-02-25  733156017254      BE42733156017254   \n",
      "4           NaT   63461819055      BE31063461819055   \n",
      "\n",
      "                              email         bic  \n",
      "0  christian22christian@hotmail.com  GEBA BE BB  \n",
      "1       k_van_den_dries@hotmail.com         NaN  \n",
      "2         kurt.vermeulen1@skynet.be         NaN  \n",
      "3             gido.imbert@skynet.be  KRED BE BB  \n",
      "4    rechina.compernolle@telenet.be  GKCC BE BB  \n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š Step 3: Data Type Standardization and Initial Cleaning\n",
    "\n",
    "print(\"\\nâœ… Starting data type standardization and cleaning process...\\n\")\n",
    "\n",
    "# ğŸ”¢ Convert 'house_number' to string (since some houses have addition like '12A')\n",
    "df['house_number'] = df['house_number'].astype(str)\n",
    "print(\"ğŸ”¹ Converted 'house_number' to string.\")\n",
    "\n",
    "# ğŸ”¢ Convert 'phone_number' and 'account_number' to string to preserve leading zeros and formatting\n",
    "df['phone_number'] = df['phone_number'].astype(str).str.replace('.0', '', regex=False)\n",
    "df['account_number'] = df['account_number'].astype(str).str.replace('.0', '', regex=False)\n",
    "print(\"ğŸ”¹ Converted 'phone_number' and 'account_number' to string and cleaned decimals.\")\n",
    "\n",
    "# ğŸ§¹ Clean 'iban': Remove all spaces for uniform formatting\n",
    "df['iban'] = df['iban'].str.replace(' ', '').str.strip()\n",
    "print(\"ğŸ”¹ Cleaned IBAN numbers by removing spaces.\")\n",
    "\n",
    "# ğŸ—“ï¸ Standardize 'date_of_birth' to datetime format\n",
    "df['date_of_birth'] = pd.to_datetime(df['date_of_birth'], errors='coerce', dayfirst=True)\n",
    "print(\"ğŸ”¹ Converted 'date_of_birth' to datetime format (NaT if invalid).\")\n",
    "\n",
    "# âœ… Clean 'postal_code': Make sure it's a string (some postal codes may start with zero)\n",
    "df['postal_code'] = df['postal_code'].astype(str).str.strip()\n",
    "print(\"ğŸ”¹ Converted 'postal_code' to string and stripped whitespace.\")\n",
    "\n",
    "# ğŸ§½ Strip leading/trailing whitespaces in textual columns (optional but professional)\n",
    "text_columns = ['gender', 'last_name', 'initials', 'infix', 'street_name', 'addition', 'city', 'email', 'bic']\n",
    "df[text_columns] = df[text_columns].apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "print(\"ğŸ”¹ Stripped whitespace from all text columns.\")\n",
    "\n",
    "# âœ… Final DataFrame Overview\n",
    "print(\"\\nğŸ” Data types after standardization:\\n\", df.dtypes)\n",
    "print(\"\\nğŸ” Preview of cleaned data:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Step 4 - Full Notebook Code & Markdown Example:\n",
    "ğŸ“¦ Code Block 1: Identifying Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking missing values per column:\n",
      "\n",
      "gender             139\n",
      "last_name            4\n",
      "initials            46\n",
      "infix             6283\n",
      "street_name          0\n",
      "house_number         0\n",
      "addition          6264\n",
      "postal_code          0\n",
      "city                 0\n",
      "phone_number         0\n",
      "date_of_birth     2995\n",
      "account_number       0\n",
      "iban                 0\n",
      "email                0\n",
      "bic                886\n",
      "dtype: int64\n",
      "\n",
      "ğŸ“Š Percentage of missing values per column:\n",
      "\n",
      "gender             1.87\n",
      "last_name          0.05\n",
      "initials           0.62\n",
      "infix             84.59\n",
      "street_name        0.00\n",
      "house_number       0.00\n",
      "addition          84.33\n",
      "postal_code        0.00\n",
      "city               0.00\n",
      "phone_number       0.00\n",
      "date_of_birth     40.32\n",
      "account_number     0.00\n",
      "iban               0.00\n",
      "email              0.00\n",
      "bic               11.93\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š Checking for missing values in each column\n",
    "print(\"ğŸ” Checking missing values per column:\\n\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# ğŸ“ Also showing percentage of missingness for stakeholders\n",
    "print(\"\\nğŸ“Š Percentage of missing values per column:\\n\")\n",
    "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "print(missing_percent.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Step 4: Handling Missing Data and Saving Clean & Garbage Files\n",
    "\n",
    "- **No rows or columns were dropped** â€” all missing values were replaced with empty strings ('').\n",
    "- **Two versions** of the dataset have been saved:\n",
    "  - **Garbage Data File** (contains blanks but retains all raw records): `belgium_bank_garbage_data.csv`\n",
    "  - **Clean Data File** (ready for analysis with blanks instead of NaNs): `belgium_bank_clean_data.csv`\n",
    "- This ensures we keep **full transparency and flexibility** for future review and decision-making.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Verifying that all missing values have been filled with blanks (should show 0 for all):\n",
      "\n",
      "gender               0\n",
      "last_name            0\n",
      "initials             0\n",
      "infix                0\n",
      "street_name          0\n",
      "house_number         0\n",
      "addition             0\n",
      "postal_code          0\n",
      "city                 0\n",
      "phone_number         0\n",
      "date_of_birth     2995\n",
      "account_number       0\n",
      "iban                 0\n",
      "email                0\n",
      "bic                  0\n",
      "dtype: int64\n",
      "\n",
      "ğŸ’¾ Garbage dataset saved successfully at: ../output/belgium_bank_garbage_data.csv\n",
      "ğŸ’¾ Clean dataset saved successfully at: ../output/belgium_bank_clean_data.csv\n"
     ]
    }
   ],
   "source": [
    "# ğŸ› ï¸ Step 4: Handling Missing Data & Saving Both Garbage and Clean Files\n",
    "\n",
    "# âœ… Replacing all missing values with empty strings to preserve all records\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# âœ… Confirming that missing values are handled\n",
    "print(\"\\nğŸ”„ Verifying that all missing values have been filled with blanks (should show 0 for all):\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ğŸ’¾ Save the \"garbage data\" version (with blanks but no removed data)\n",
    "garbage_file_path = '../output/belgium_bank_garbage_data.csv'\n",
    "df.to_csv(garbage_file_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nğŸ’¾ Garbage dataset saved successfully at: {garbage_file_path}\")\n",
    "\n",
    "# ğŸ’¾ Save the \"clean data\" version for analysis\n",
    "clean_file_path = '../output/belgium_bank_clean_data.csv'\n",
    "df.to_csv(clean_file_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"ğŸ’¾ Clean dataset saved successfully at: {clean_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Data Consistency & Validation\n",
    "\n",
    "In this step, we will focus on **validating critical fields** such as IBAN, BIC, phone numbers, and dates of birth to ensure they follow expected formats. This is essential to maintain high-quality, reliable datasets for analysis and downstream use.\n",
    "\n",
    "### âœ… Fields to Validate:\n",
    "1. **IBAN Numbers** - Correct Belgian IBAN format.\n",
    "2. **Phone Numbers** - Expected length and numeric format.\n",
    "3. **Date of Birth** - Detect invalid/missing dates.\n",
    "4. **BIC Codes** - Proper format and length (typically 8 or 11 characters).\n",
    "5. **Duplicate Checks** - Avoid double entries (e.g., same IBAN or email).\n",
    "\n",
    "Let's start!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cleaned dataset loaded for validation. Number of records: 24\n",
      "    gender last_name initials infix              street_name house_number  \\\n",
      "122    Dhr   Petegem        G   Van         Kunnenbergstraat            8   \n",
      "309   Mevr   Verwimp        F        P.Van Langendonckstraat           19   \n",
      "560      V     Melis       A.               Winterslagstraat          105   \n",
      "\n",
      "    addition postal_code        city phone_number date_of_birth  \\\n",
      "122                 9660      Brakel    495211164    1973-12-17   \n",
      "309                 9050  Gentbrugge     92314605                 \n",
      "560    Bus 1        3600     Centrum    486405695    1966-09-20   \n",
      "\n",
      "       account_number              iban                        email  \\\n",
      "122  780581655863      BE40780581655863      adarma.lieve@telenet.be   \n",
      "309    1105666826      BE59001105666826  florette.verwimp@telenet.be   \n",
      "560    1645777172      BE38001645777172         Melisanita@gmail.com   \n",
      "\n",
      "          bic validation_issues  \n",
      "122  GKCCBEBB                OK  \n",
      "309  GEBABEBB                OK  \n",
      "560  GEBABEBB                OK  \n",
      "âš ï¸ Found 0 invalid IBAN(s).\n",
      "Empty DataFrame\n",
      "Columns: [iban]\n",
      "Index: []\n",
      "ğŸ’¾ Invalid IBANs saved to 'output/belgium_bank_invalid_iban.csv'.\n",
      "âš ï¸ Found 0 invalid phone number(s).\n",
      "Empty DataFrame\n",
      "Columns: [phone_number]\n",
      "Index: []\n",
      "ğŸ’¾ Invalid phone numbers saved to 'output/belgium_bank_invalid_phone.csv'.\n",
      "âš ï¸ Found 0 invalid BIC(s).\n",
      "Empty DataFrame\n",
      "Columns: [bic]\n",
      "Index: []\n",
      "ğŸ’¾ Invalid BICs saved to 'output/belgium_bank_invalid_bic.csv'.\n"
     ]
    }
   ],
   "source": [
    "# âœ… Cleaned dataset loaded for validation\n",
    "print(\"âœ… Cleaned dataset loaded for validation. Number of records:\", len(clean_data))\n",
    "print(clean_data.head(3))  # Quick peek\n",
    "\n",
    "# ------------------- IBAN Validation ------------------- #\n",
    "# IBAN must start with 'BE' followed by 14 digits\n",
    "invalid_iban = clean_data[~clean_data['iban'].str.match(r'^BE\\d{14}$')]\n",
    "print(f\"âš ï¸ Found {len(invalid_iban)} invalid IBAN(s).\")\n",
    "print(invalid_iban[['iban']].head(5))\n",
    "invalid_iban.to_csv('../output/belgium_bank_invalid_iban.csv', index=False)\n",
    "print(\"ğŸ’¾ Invalid IBANs saved to 'output/belgium_bank_invalid_iban.csv'.\")\n",
    "\n",
    "# ------------------- Phone Number Validation ------------------- #\n",
    "# Ensure column is string and fill blanks\n",
    "clean_data['phone_number'] = clean_data['phone_number'].fillna('').astype(str)\n",
    "\n",
    "# Check for numeric-only, 8-10 digits\n",
    "invalid_phone = clean_data[~clean_data['phone_number'].str.match(r'^\\d{8,10}$')]\n",
    "print(f\"âš ï¸ Found {len(invalid_phone)} invalid phone number(s).\")\n",
    "print(invalid_phone[['phone_number']].head(5))\n",
    "invalid_phone.to_csv('../output/belgium_bank_invalid_phone.csv', index=False)\n",
    "print(\"ğŸ’¾ Invalid phone numbers saved to 'output/belgium_bank_invalid_phone.csv'.\")\n",
    "\n",
    "# ------------------- BIC Validation ------------------- #\n",
    "# BIC must be 8 or 11 alphanumeric characters\n",
    "clean_data['bic'] = clean_data['bic'].fillna('').astype(str)  # Ensure string type\n",
    "invalid_bic = clean_data[\n",
    "    (clean_data['bic'] != '') &\n",
    "    (~clean_data['bic'].str.match(r'^[A-Z0-9]{8}([A-Z0-9]{3})?$'))\n",
    "]\n",
    "print(f\"âš ï¸ Found {len(invalid_bic)} invalid BIC(s).\")\n",
    "print(invalid_bic[['bic']].head(5))\n",
    "invalid_bic.to_csv('../output/belgium_bank_invalid_bic.csv', index=False)\n",
    "print(\"ğŸ’¾ Invalid BICs saved to 'output/belgium_bank_invalid_bic.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Fix Phone and BIC Issues + Re-run Validations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Found 0 invalid phone number(s) AFTER FIX.\n",
      "Empty DataFrame\n",
      "Columns: [phone_number]\n",
      "Index: []\n",
      "ğŸ’¾ Invalid phone numbers saved to 'output/belgium_bank_invalid_phone.csv'.\n",
      "âš ï¸ Found 0 invalid BIC(s) AFTER FIX.\n",
      "Empty DataFrame\n",
      "Columns: [bic]\n",
      "Index: []\n",
      "ğŸ’¾ Invalid BICs saved to 'output/belgium_bank_invalid_bic.csv'.\n"
     ]
    }
   ],
   "source": [
    "# âœ… Fix phone number: remove decimals and spaces\n",
    "clean_data['phone_number'] = clean_data['phone_number'].fillna('').astype(str).str.replace(r'\\.0$', '', regex=True).str.strip()\n",
    "\n",
    "# âœ… Fix BIC: remove spaces\n",
    "clean_data['bic'] = clean_data['bic'].fillna('').astype(str).str.replace(' ', '').str.strip()\n",
    "\n",
    "# ------------------- Re-run Phone Number Validation ------------------- #\n",
    "invalid_phone = clean_data[~clean_data['phone_number'].str.match(r'^\\d{8,10}$')]\n",
    "print(f\"âš ï¸ Found {len(invalid_phone)} invalid phone number(s) AFTER FIX.\")\n",
    "print(invalid_phone[['phone_number']].head(5))\n",
    "invalid_phone.to_csv('../output/belgium_bank_invalid_phone.csv', index=False)\n",
    "print(\"ğŸ’¾ Invalid phone numbers saved to 'output/belgium_bank_invalid_phone.csv'.\")\n",
    "\n",
    "# ------------------- Re-run BIC Validation ------------------- #\n",
    "invalid_bic = clean_data[\n",
    "    (clean_data['bic'] != '') &\n",
    "    (~clean_data['bic'].str.match(r'^[A-Z0-9]{8}([A-Z0-9]{3})?$'))\n",
    "]\n",
    "print(f\"âš ï¸ Found {len(invalid_bic)} invalid BIC(s) AFTER FIX.\")\n",
    "print(invalid_bic[['bic']].head(5))\n",
    "invalid_bic.to_csv('../output/belgium_bank_invalid_bic.csv', index=False)\n",
    "print(\"ğŸ’¾ Invalid BICs saved to 'output/belgium_bank_invalid_bic.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š Step 5: Final Validation & Correction of Belgium Bank Dataset\n",
    "In this step, we perform **final checks** and corrections on:\n",
    "- **Phone Numbers**: Ensuring correct numeric format, length.\n",
    "- **BIC Codes**: Proper format, length, uppercase without spaces.\n",
    "\n",
    "We'll also re-validate for any remaining issues and save final datasets.\n",
    "\n",
    "**Deliverables:**\n",
    "- `belgium_bank_clean_data_final.csv`: Final cleaned data\n",
    "- `belgium_bank_invalid_phone.csv`: Remaining invalid phone numbers (if any)\n",
    "- `belgium_bank_invalid_bic.csv`: Remaining invalid BIC codes (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Found 0 invalid email(s).\n",
      "Empty DataFrame\n",
      "Columns: [email]\n",
      "Index: []\n",
      "ğŸ’¾ Invalid emails saved to 'output/belgium_bank_invalid_emails.csv'.\n",
      "âš ï¸ Found 0 invalid phone number(s) AFTER FIX.\n",
      "Empty DataFrame\n",
      "Columns: [phone_number]\n",
      "Index: []\n",
      "ğŸ’¾ Invalid phone numbers saved to 'output/belgium_bank_invalid_phone.csv'.\n",
      "âš ï¸ Found 0 invalid BIC(s) AFTER FIX.\n",
      "Empty DataFrame\n",
      "Columns: [bic]\n",
      "Index: []\n",
      "ğŸ’¾ Invalid BICs saved to 'output/belgium_bank_invalid_bic.csv'.\n",
      "âš ï¸ Total invalid IBANs detected: 0\n",
      "ğŸ” Sample of invalid IBANs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>initials</th>\n",
       "      <th>infix</th>\n",
       "      <th>street_name</th>\n",
       "      <th>house_number</th>\n",
       "      <th>addition</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>city</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>account_number</th>\n",
       "      <th>iban</th>\n",
       "      <th>email</th>\n",
       "      <th>bic</th>\n",
       "      <th>validation_issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gender, last_name, initials, infix, street_name, house_number, addition, postal_code, city, phone_number, date_of_birth, account_number, iban, email, bic, validation_issues]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# âœ… Ensure phone_number is string and NaNs are empty strings\n",
    "clean_data['phone_number'] = clean_data['phone_number'].fillna('').astype(str)\n",
    "\n",
    "# âœ… Remove non-digit characters\n",
    "clean_data['phone_number'] = clean_data['phone_number'].str.replace(r'\\D', '', regex=True)\n",
    "\n",
    "\n",
    "\n",
    "# Validate email format using regex\n",
    "email_pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
    "invalid_emails = clean_data[~clean_data['email'].str.match(email_pattern, na=False)]\n",
    "\n",
    "print(f\"âš ï¸ Found {len(invalid_emails)} invalid email(s).\")\n",
    "print(invalid_emails[['email']].head())\n",
    "\n",
    "# Optionally save for review\n",
    "invalid_emails.to_csv('../output/belgium_bank_invalid_emails.csv', index=False)\n",
    "print(\"ğŸ’¾ Invalid emails saved to 'output/belgium_bank_invalid_emails.csv'.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# âœ… Now safely apply regex check for valid 8-10 digit phone numbers\n",
    "invalid_phone = clean_data[~clean_data['phone_number'].str.match(r'^\\d{8,10}$', na=False)]\n",
    "\n",
    "print(f\"âš ï¸ Found {len(invalid_phone)} invalid phone number(s) AFTER FIX.\")\n",
    "print(invalid_phone[['phone_number']].head())\n",
    "\n",
    "# ğŸ’¾ Save invalid phone numbers\n",
    "invalid_phone.to_csv('../output/belgium_bank_invalid_phone.csv', index=False)\n",
    "print(\"ğŸ’¾ Invalid phone numbers saved to 'output/belgium_bank_invalid_phone.csv'.\")\n",
    "\n",
    "# âœ… Fix BICs: ensure string type, fill NaNs, remove spaces, and uppercase\n",
    "clean_data['bic'] = clean_data['bic'].fillna('').astype(str).str.replace(r'\\s+', '', regex=True).str.upper()\n",
    "\n",
    "# âœ… Validate BICs (8 or 11 alphanumeric characters)\n",
    "invalid_bic = clean_data[\n",
    "    (clean_data['bic'] != '') &  # Not empty\n",
    "    (~clean_data['bic'].str.match(r'^[A-Z0-9]{8}([A-Z0-9]{3})?$', na=False))\n",
    "]\n",
    "\n",
    "print(f\"âš ï¸ Found {len(invalid_bic)} invalid BIC(s) AFTER FIX.\")\n",
    "print(invalid_bic[['bic']].head())\n",
    "\n",
    "# ğŸ’¾ Save invalid BICs\n",
    "invalid_bic.to_csv('../output/belgium_bank_invalid_bic.csv', index=False)\n",
    "print(\"ğŸ’¾ Invalid BICs saved to 'output/belgium_bank_invalid_bic.csv'.\")\n",
    "\n",
    "# ğŸ“‚ Load Invalid IBAN File\n",
    "invalid_iban_path = '../output/belgium_bank_invalid_iban.csv'\n",
    "invalid_iban = pd.read_csv(invalid_iban_path)\n",
    "\n",
    "# Display summary\n",
    "print(f\"âš ï¸ Total invalid IBANs detected: {len(invalid_iban)}\")\n",
    "print(\"ğŸ” Sample of invalid IBANs:\")\n",
    "display(invalid_iban.head(10))  # Display top 10 as sample\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š Step 5: Full Dataset Inspection & Final Cleaning Actions\n",
    "\n",
    "In this step, we will:\n",
    "\n",
    "1. Inspect data types and value distributions to ensure everything looks consistent.\n",
    "2. Perform validation and cleaning for **email addresses**.\n",
    "3. Perform validation and cleaning for **names** (first and last names, initials).\n",
    "4. Check and handle **duplicate rows** based on critical identifiers.\n",
    "5. Export the fully cleaned dataset for analysis.\n",
    "\n",
    "This step ensures that we **finalize the dataset quality** before moving into analysis and modeling phases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>initials</th>\n",
       "      <th>infix</th>\n",
       "      <th>street_name</th>\n",
       "      <th>house_number</th>\n",
       "      <th>addition</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>city</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>account_number</th>\n",
       "      <th>iban</th>\n",
       "      <th>email</th>\n",
       "      <th>bic</th>\n",
       "      <th>validation_issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Dhr</td>\n",
       "      <td>Petegem</td>\n",
       "      <td>G</td>\n",
       "      <td>Van</td>\n",
       "      <td>Kunnenbergstraat</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>9660</td>\n",
       "      <td>Brakel</td>\n",
       "      <td>495211164</td>\n",
       "      <td>1973-12-17</td>\n",
       "      <td>780581655863</td>\n",
       "      <td>BE40780581655863</td>\n",
       "      <td>adarma.lieve@telenet.be</td>\n",
       "      <td>GKCCBEBB</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Mevr</td>\n",
       "      <td>Verwimp</td>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td>P.Van Langendonckstraat</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td>9050</td>\n",
       "      <td>Gentbrugge</td>\n",
       "      <td>92314605</td>\n",
       "      <td></td>\n",
       "      <td>1105666826</td>\n",
       "      <td>BE59001105666826</td>\n",
       "      <td>florette.verwimp@telenet.be</td>\n",
       "      <td>GEBABEBB</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>V</td>\n",
       "      <td>Melis</td>\n",
       "      <td>A.</td>\n",
       "      <td></td>\n",
       "      <td>Winterslagstraat</td>\n",
       "      <td>105</td>\n",
       "      <td>Bus 1</td>\n",
       "      <td>3600</td>\n",
       "      <td>Centrum</td>\n",
       "      <td>486405695</td>\n",
       "      <td>1966-09-20</td>\n",
       "      <td>1645777172</td>\n",
       "      <td>BE38001645777172</td>\n",
       "      <td>Melisanita@gmail.com</td>\n",
       "      <td>GEBABEBB</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>Dhr</td>\n",
       "      <td>Bals</td>\n",
       "      <td>P</td>\n",
       "      <td></td>\n",
       "      <td>Vossekotstraat</td>\n",
       "      <td>62</td>\n",
       "      <td></td>\n",
       "      <td>9100</td>\n",
       "      <td>St-Niklaas</td>\n",
       "      <td>478234393</td>\n",
       "      <td>1971-01-16</td>\n",
       "      <td>293056336140</td>\n",
       "      <td>BE02293056336140</td>\n",
       "      <td>bals_peter@telenet.be</td>\n",
       "      <td>GEBABEBB</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>Mevr</td>\n",
       "      <td>Boutens</td>\n",
       "      <td>R</td>\n",
       "      <td></td>\n",
       "      <td>Kortrijkessteenweg</td>\n",
       "      <td>84</td>\n",
       "      <td></td>\n",
       "      <td>9800</td>\n",
       "      <td>Denzie</td>\n",
       "      <td>499159550</td>\n",
       "      <td></td>\n",
       "      <td>63450274439</td>\n",
       "      <td>BE13063450274439</td>\n",
       "      <td>BT.rosita@hotmail.be</td>\n",
       "      <td>GKCCBEBB</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender last_name initials infix              street_name house_number  \\\n",
       "122     Dhr   Petegem        G   Van         Kunnenbergstraat            8   \n",
       "309    Mevr   Verwimp        F        P.Van Langendonckstraat           19   \n",
       "560       V     Melis       A.               Winterslagstraat          105   \n",
       "1568    Dhr      Bals        P                 Vossekotstraat           62   \n",
       "1675   Mevr   Boutens        R             Kortrijkessteenweg           84   \n",
       "\n",
       "     addition postal_code        city phone_number date_of_birth  \\\n",
       "122                  9660      Brakel    495211164    1973-12-17   \n",
       "309                  9050  Gentbrugge     92314605                 \n",
       "560     Bus 1        3600     Centrum    486405695    1966-09-20   \n",
       "1568                 9100  St-Niklaas    478234393    1971-01-16   \n",
       "1675                 9800      Denzie    499159550                 \n",
       "\n",
       "        account_number              iban                        email  \\\n",
       "122   780581655863      BE40780581655863      adarma.lieve@telenet.be   \n",
       "309     1105666826      BE59001105666826  florette.verwimp@telenet.be   \n",
       "560     1645777172      BE38001645777172         Melisanita@gmail.com   \n",
       "1568  293056336140      BE02293056336140        bals_peter@telenet.be   \n",
       "1675   63450274439      BE13063450274439         BT.rosita@hotmail.be   \n",
       "\n",
       "           bic validation_issues  \n",
       "122   GKCCBEBB                OK  \n",
       "309   GEBABEBB                OK  \n",
       "560   GEBABEBB                OK  \n",
       "1568  GEBABEBB                OK  \n",
       "1675  GKCCBEBB                OK  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Data Types:\n",
      "gender               object\n",
      "last_name            object\n",
      "initials             object\n",
      "infix                object\n",
      "street_name          object\n",
      "house_number         object\n",
      "addition             object\n",
      "postal_code          object\n",
      "city                 object\n",
      "phone_number         object\n",
      "date_of_birth        object\n",
      "account_number       object\n",
      "iban                 object\n",
      "email                object\n",
      "bic                  object\n",
      "validation_issues    object\n",
      "dtype: object\n",
      "\n",
      "ğŸ”¢ Dataset shape (rows, columns): (24, 16)\n",
      "\n",
      "ğŸ“Š Checking null counts per column:\n",
      "gender               0\n",
      "last_name            0\n",
      "initials             0\n",
      "infix                0\n",
      "street_name          0\n",
      "house_number         0\n",
      "addition             0\n",
      "postal_code          0\n",
      "city                 0\n",
      "phone_number         0\n",
      "date_of_birth        0\n",
      "account_number       0\n",
      "iban                 0\n",
      "email                0\n",
      "bic                  0\n",
      "validation_issues    0\n",
      "dtype: int64\n",
      "\n",
      "ğŸ“Š Unique counts in each column:\n",
      "gender                5\n",
      "last_name            23\n",
      "initials             21\n",
      "infix                 4\n",
      "street_name          23\n",
      "house_number         22\n",
      "addition              2\n",
      "postal_code          21\n",
      "city                 21\n",
      "phone_number         23\n",
      "date_of_birth        11\n",
      "account_number       23\n",
      "iban                 23\n",
      "email                23\n",
      "bic                   8\n",
      "validation_issues     1\n",
      "dtype: int64\n",
      "\n",
      "ğŸ¯ Checking summary statistics for numeric-looking fields:\n",
      "                  count unique                      top freq\n",
      "gender               24      5                        V    9\n",
      "last_name            24     23                   Helson    2\n",
      "initials             24     21                       C.    2\n",
      "infix                24      4                            21\n",
      "street_name          24     23               Rue Ferrer    2\n",
      "house_number         24     22                       16    2\n",
      "addition             24      2                            23\n",
      "postal_code          24     21                     8500    2\n",
      "city                 24     21                 Kortrijk    2\n",
      "phone_number         24     23                478325760    2\n",
      "date_of_birth        24     11                            14\n",
      "account_number       24     23           1281569959        2\n",
      "iban                 24     23         BE84001281569959    2\n",
      "email                24     23  fannyhelson@hotmail.com    2\n",
      "bic                  24      8                 GKCCBEBB    7\n",
      "validation_issues    24      1                       OK   24\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” Inspect basic information\n",
    "print(\"âœ… Dataset Preview:\")\n",
    "display(clean_data.head(5))\n",
    "\n",
    "print(\"\\nâœ… Data Types:\")\n",
    "print(clean_data.dtypes)\n",
    "\n",
    "print(\"\\nğŸ”¢ Dataset shape (rows, columns):\", clean_data.shape)\n",
    "\n",
    "print(\"\\nğŸ“Š Checking null counts per column:\")\n",
    "print(clean_data.isnull().sum())\n",
    "\n",
    "print(\"\\nğŸ“Š Unique counts in each column:\")\n",
    "print(clean_data.nunique())\n",
    "\n",
    "print(\"\\nğŸ¯ Checking summary statistics for numeric-looking fields:\")\n",
    "print(clean_data.describe(include='all').transpose())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Final Code Block with Markdown for Names Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded. Shape: (7428, 15)\n",
      "\n",
      "ğŸ” Preview after name standardization:\n",
      "     last_name initials    infix\n",
      "0       Jacobs       C.         \n",
      "1        Dries       K.  Van Den\n",
      "2    Vermeulen     KURT         \n",
      "3     Oirschot       L.      Van\n",
      "4  Compernolle       R.         \n",
      "5      Taalman       M.         \n",
      "6  Blauwblomme       V.         \n",
      "7  El-Khattabi       R.         \n",
      "8       Jannis       Y.         \n",
      "9     Vlaminck       C.         \n",
      "\n",
      "ğŸ’¾ Cleaned dataset with fixed names saved to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_with_fixed_names.csv\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# ## âœ¨ Step 1: Standardizing Names (Last Names, Initials, Infix)\n",
    "# - Title-case all last names and infix (e.g., \"van\" to \"Van\")\n",
    "# - Upper-case initials (e.g., \"k.\" to \"K.\")\n",
    "# - Strip extra spaces and handle blanks\n",
    "# ---\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# âœ… Load the working clean dataset\n",
    "file_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data.csv'\n",
    "df = pd.read_csv(file_path, dtype=str)\n",
    "print(\"âœ… Dataset loaded. Shape:\", df.shape)\n",
    "\n",
    "# âœ… Fill NaNs as blanks for consistency\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# âœ… Strip and format names properly\n",
    "df['last_name'] = df['last_name'].str.strip().str.title()  # Title case, strip spaces\n",
    "df['initials'] = df['initials'].str.strip().str.upper()   # Upper case, strip spaces\n",
    "df['infix'] = df['infix'].str.strip().str.title()         # Title case, strip spaces\n",
    "\n",
    "# âœ… Preview to confirm the transformation\n",
    "print(\"\\nğŸ” Preview after name standardization:\")\n",
    "print(df[['last_name', 'initials', 'infix']].head(10))\n",
    "\n",
    "# âœ… Save updated dataset to a new clean file\n",
    "output_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_with_fixed_names.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nğŸ’¾ Cleaned dataset with fixed names saved to: {output_path}\")\n",
    "\n",
    "# ---\n",
    "# âœ… Summary:\n",
    "# - Names properly formatted\n",
    "# - Dataset ready for next steps (email/IBAN/BIC/duplicates)\n",
    "# ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Corrected Approach for Email Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded. Shape: (7428, 15)\n",
      "âš ï¸ Found 8 invalid email(s).\n",
      "ğŸ’¾ Invalid email rows saved to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv\n",
      "ğŸ’¾ Updated clean dataset saved to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_emails_valid.csv\n",
      "\n",
      "ğŸ“Š Email Cleaning Summary:\n",
      "Total records retained: 7428\n",
      "Invalid emails moved to garbage file: 8\n",
      "ğŸš€ Ready for next cleaning step (phone, BIC, IBAN)!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ Step 2: Email Validation (Retain all rows, separate invalid emails)\n",
    "\n",
    "\n",
    "# ğŸ”½ Load dataset with fixed names\n",
    "file_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_with_fixed_names.csv'\n",
    "df = pd.read_csv(file_path, dtype=str)\n",
    "print(f\"âœ… Dataset loaded. Shape: {df.shape}\")\n",
    "\n",
    "# ğŸ§½ Fill blanks and strip whitespaces for safety\n",
    "df['email'] = df['email'].fillna('').str.strip()\n",
    "\n",
    "# âœ… Email validation pattern\n",
    "email_pattern = r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\"\n",
    "\n",
    "# ğŸ” Detect invalid emails\n",
    "invalid_email_mask = ~df['email'].str.match(email_pattern, na=False)\n",
    "invalid_emails_df = df[invalid_email_mask].copy()\n",
    "print(f\"âš ï¸ Found {len(invalid_emails_df)} invalid email(s).\")\n",
    "\n",
    "# ğŸ’¾ Save rows with invalid emails to garbage file for review\n",
    "garbage_output_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv'\n",
    "invalid_emails_df.to_csv(garbage_output_path, index=False)\n",
    "print(f\"ğŸ’¾ Invalid email rows saved to: {garbage_output_path}\")\n",
    "\n",
    "# ğŸ§¹ Blank out invalid emails in main dataset (retain row)\n",
    "df.loc[invalid_email_mask, 'email'] = ''\n",
    "\n",
    "# ğŸ’¾ Save updated clean dataset (emails cleaned)\n",
    "clean_emails_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_emails_valid.csv'\n",
    "df.to_csv(clean_emails_path, index=False)\n",
    "print(f\"ğŸ’¾ Updated clean dataset saved to: {clean_emails_path}\")\n",
    "\n",
    "# âœ… Summary\n",
    "print(\"\\nğŸ“Š Email Cleaning Summary:\")\n",
    "print(f\"Total records retained: {len(df)}\")\n",
    "print(f\"Invalid emails moved to garbage file: {len(invalid_emails_df)}\")\n",
    "print(\"ğŸš€ Ready for next cleaning step (phone, BIC, IBAN)!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---\n",
    "# ## ğŸ“ Phone Number Validation & Cleanup\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded. Shape: (7428, 15)\n",
      "âš ï¸ Found 11 invalid phone number(s).\n",
      "     phone_number\n",
      "144           NaN\n",
      "335   5.37014e+17\n",
      "1581            3\n",
      "2820          NaN\n",
      "2821          NaN\n",
      "ğŸ’¾ Invalid phone numbers added to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv\n",
      "ğŸ’¾ Updated clean dataset saved to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_phones_valid.csv\n",
      "\n",
      "ğŸ“Š Phone Number Cleaning Summary:\n",
      "Total records retained: 7428\n",
      "Invalid phone numbers moved to garbage file: 11\n",
      "ğŸš€ Ready for next cleaning step (BIC or IBAN)!\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# ## ğŸ“ Phone Number Validation & Cleanup\n",
    "# ---\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# âœ… Load the current working clean dataset\n",
    "file_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_emails_valid.csv'\n",
    "df = pd.read_csv(file_path, dtype=str)\n",
    "print(\"âœ… Dataset loaded. Shape:\", df.shape)\n",
    "\n",
    "# âœ… Define phone number validation pattern (8 to 10 digits only)\n",
    "phone_pattern = r\"^\\d{8,10}$\"\n",
    "\n",
    "# ========================\n",
    "# STEP 1: Find Invalid Phones\n",
    "# ========================\n",
    "invalid_phone_mask = ~df['phone_number'].str.match(phone_pattern, na=False)\n",
    "invalid_phones = df[invalid_phone_mask].copy()\n",
    "\n",
    "print(f\"âš ï¸ Found {len(invalid_phones)} invalid phone number(s).\")\n",
    "print(invalid_phones[['phone_number']].head())\n",
    "\n",
    "# ========================\n",
    "# STEP 2: Add Invalid Phones to Garbage File\n",
    "# ========================\n",
    "# Load existing garbage file to append\n",
    "garbage_file_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv'\n",
    "try:\n",
    "    garbage_df = pd.read_csv(garbage_file_path, dtype=str)\n",
    "except FileNotFoundError:\n",
    "    garbage_df = pd.DataFrame()  # Create empty DataFrame if doesn't exist yet\n",
    "\n",
    "# Append new invalid phones\n",
    "updated_garbage_df = pd.concat([garbage_df, invalid_phones], ignore_index=True)\n",
    "\n",
    "# Save updated garbage\n",
    "updated_garbage_df.to_csv(garbage_file_path, index=False)\n",
    "print(f\"ğŸ’¾ Invalid phone numbers added to: {garbage_file_path}\")\n",
    "\n",
    "# ========================\n",
    "# STEP 3: Blank Invalid Phone Numbers in Clean Dataset\n",
    "# ========================\n",
    "df.loc[invalid_phone_mask, 'phone_number'] = ''\n",
    "\n",
    "# ========================\n",
    "# STEP 4: Save Updated Clean Dataset\n",
    "# ========================\n",
    "clean_output_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_phones_valid.csv'\n",
    "df.to_csv(clean_output_path, index=False)\n",
    "print(f\"ğŸ’¾ Updated clean dataset saved to: {clean_output_path}\")\n",
    "\n",
    "# ========================\n",
    "# âœ… STEP 5: Summary\n",
    "# ========================\n",
    "print(\"\\nğŸ“Š Phone Number Cleaning Summary:\")\n",
    "print(\"Total records retained:\", len(df))\n",
    "print(\"Invalid phone numbers moved to garbage file:\", len(invalid_phones))\n",
    "print(\"ğŸš€ Ready for next cleaning step (BIC or IBAN)!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Step: BIC (Bank Identifier Code) Validation & Cleanup\n",
    "ğŸ“Œ Goal:\n",
    "Check that all BIC values follow correct format:\n",
    "8 or 11 characters, uppercase, letters and/or digits.\n",
    "Invalid BICs â¡ï¸ moved to garbage file AND replaced with blank in the clean dataset (NO row deletions!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Final Consolidation Code Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded dataset for finalization: (7428, 15)\n",
      "ğŸ—‘ï¸ Dropped 'bic' column.\n",
      "ğŸ’¾ Final clean dataset saved to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final.csv\n",
      "ğŸ’¾ All garbage data consolidated to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load last cleaned dataset\n",
    "final_clean_file = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_phones_valid.csv'\n",
    "df = pd.read_csv(final_clean_file, dtype=str)\n",
    "\n",
    "print(\"âœ… Loaded dataset for finalization:\", df.shape)\n",
    "\n",
    "# Drop BIC (based on previous decision)\n",
    "if 'bic' in df.columns:\n",
    "    df.drop(columns=['bic'], inplace=True)\n",
    "    print(\"ğŸ—‘ï¸ Dropped 'bic' column.\")\n",
    "\n",
    "# Final formatting check (strip whitespace)\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].fillna('').astype(str).str.strip()\n",
    "\n",
    "# Save final clean file\n",
    "final_output_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final.csv'\n",
    "df.to_csv(final_output_path, index=False)\n",
    "print(f\"ğŸ’¾ Final clean dataset saved to: {final_output_path}\")\n",
    "\n",
    "# (Optional) Combine all garbage files into one\n",
    "garbage_files = [\n",
    "    r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv',\n",
    "    # Add paths to other specific garbage datasets if not yet combined\n",
    "]\n",
    "garbage_dfs = [pd.read_csv(file, dtype=str) for file in garbage_files]\n",
    "combined_garbage = pd.concat(garbage_dfs, ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Save combined garbage data\n",
    "combined_garbage_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv'\n",
    "combined_garbage.to_csv(combined_garbage_path, index=False)\n",
    "print(f\"ğŸ’¾ All garbage data consolidated to: {combined_garbage_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Hereâ€™s the code to execute this step properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded. Shape: (7428, 14)\n",
      "âš ï¸ Found 29 invalid IBAN(s).\n",
      "ğŸ” Sample of invalid IBANs:\n",
      "                   iban\n",
      "545     BE3773740389328\n",
      "803     BE3406345244590\n",
      "884     BE4063453276789\n",
      "1574  BBE70464520761125\n",
      "1901    BE9293057720614\n",
      "ğŸ’¾ Updated clean dataset saved to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final.csv\n",
      "ğŸ’¾ Invalid IBAN rows added to garbage file: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv\n",
      "\n",
      "ğŸ“Š IBAN Cleaning Summary:\n",
      "âœ… Clean dataset shape: (7399, 14)\n",
      "ğŸ—‘ï¸ Garbage dataset shape: (7018, 15)\n",
      "ğŸš€ Ready for ingestion with valid IBANs only!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Imports\n",
    "import pandas as pd\n",
    "\n",
    "# âœ… Load final working dataset\n",
    "file_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final.csv'\n",
    "df = pd.read_csv(file_path, dtype=str)\n",
    "\n",
    "print(\"âœ… Dataset loaded. Shape:\", df.shape)\n",
    "\n",
    "# ================================\n",
    "# STEP 1: IBAN Validation Pattern\n",
    "# ================================\n",
    "iban_pattern = r'^BE\\d{14}$'\n",
    "\n",
    "# ================================\n",
    "# STEP 2: Clean IBAN Column\n",
    "# ================================\n",
    "# Strip spaces and upper case\n",
    "df['iban'] = df['iban'].fillna('').str.replace(' ', '').str.upper().str.strip()\n",
    "\n",
    "# ================================\n",
    "# STEP 3: Find Invalid IBANs\n",
    "# ================================\n",
    "invalid_iban_mask = ~df['iban'].str.match(iban_pattern, na=False)\n",
    "\n",
    "invalid_ibans = df.loc[invalid_iban_mask, ['iban']].copy()\n",
    "print(f\"âš ï¸ Found {len(invalid_ibans)} invalid IBAN(s).\")\n",
    "print(\"ğŸ” Sample of invalid IBANs:\")\n",
    "print(invalid_ibans.head())\n",
    "\n",
    "# ================================\n",
    "# STEP 4: Save Invalid IBANs to Garbage\n",
    "# ================================\n",
    "# Load current garbage data to append invalid IBANs\n",
    "garbage_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv'\n",
    "try:\n",
    "    garbage_df = pd.read_csv(garbage_path, dtype=str)\n",
    "except FileNotFoundError:\n",
    "    garbage_df = pd.DataFrame()  # If no file exists yet\n",
    "\n",
    "# Append only the invalid IBAN rows with full context\n",
    "invalid_iban_full_rows = df.loc[invalid_iban_mask].copy()\n",
    "garbage_df = pd.concat([garbage_df, invalid_iban_full_rows], ignore_index=True)\n",
    "\n",
    "# Drop the invalid IBAN rows from the clean dataset\n",
    "df_clean_final = df.loc[~invalid_iban_mask].copy()\n",
    "\n",
    "# ================================\n",
    "# STEP 5: Save Updated Files\n",
    "# ================================\n",
    "# Save updated clean dataset (OVERWRITE final clean file)\n",
    "df_clean_final.to_csv(file_path, index=False)\n",
    "print(f\"ğŸ’¾ Updated clean dataset saved to: {file_path}\")\n",
    "\n",
    "# Save updated garbage file\n",
    "garbage_df.to_csv(garbage_path, index=False)\n",
    "print(f\"ğŸ’¾ Invalid IBAN rows added to garbage file: {garbage_path}\")\n",
    "\n",
    "# ================================\n",
    "# STEP 6: Final Summary\n",
    "# ================================\n",
    "print(\"\\nğŸ“Š IBAN Cleaning Summary:\")\n",
    "print(\"âœ… Clean dataset shape:\", df_clean_final.shape)\n",
    "print(\"ğŸ—‘ï¸ Garbage dataset shape:\", garbage_df.shape)\n",
    "print(\"ğŸš€ Ready for ingestion with valid IBANs only!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Step 1: Python Fix for Scientific Notation in account_number\n",
    "Here is fully prepared code to fix it in-place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded. Shape: (7399, 11)\n",
      "âœ… Scientific notation fixed in 'account_number'.\n",
      "0      1462596514\n",
      "1    860000000000\n",
      "2    737000000000\n",
      "3    733000000000\n",
      "4     63461819055\n",
      "5     63456572365\n",
      "6    310000000000\n",
      "7             NaN\n",
      "8    980000000000\n",
      "9      1119838728\n",
      "Name: account_number, dtype: object\n",
      "ğŸ’¾ Cleaned data saved back to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ğŸ”¹ Load the dataset from correct file path\n",
    "file_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv'\n",
    "df = pd.read_csv(file_path, dtype=str)  # Read all columns as string to avoid numeric auto-formatting\n",
    "\n",
    "print(\"âœ… Dataset loaded. Shape:\", df.shape)\n",
    "\n",
    "# ğŸ”¹ Function to convert scientific notation to plain number\n",
    "def fix_scientific_notation(value):\n",
    "    try:\n",
    "        if 'E' in str(value).upper():\n",
    "            # Convert to float and format without scientific notation\n",
    "            return '{0:.0f}'.format(float(value))\n",
    "        else:\n",
    "            return value  # Leave as is if not scientific notation\n",
    "    except:\n",
    "        return value  # Leave as is if conversion fails\n",
    "\n",
    "# ğŸ”¹ Apply function to 'account_number' column\n",
    "df['account_number'] = df['account_number'].apply(fix_scientific_notation)\n",
    "\n",
    "print(\"âœ… Scientific notation fixed in 'account_number'.\")\n",
    "print(df['account_number'].head(10))  # Preview for verification\n",
    "\n",
    "# ğŸ”¹ Save back to same file for Data Wrangler / stakeholder use\n",
    "df.to_csv(file_path, index=False)\n",
    "print(f\"ğŸ’¾ Cleaned data saved back to: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Optional Refinement (If you want more explicit placeholders):\n",
    "Instead of \"\", you could use clear markers like 'Unknown', '0000', or 'N/A' for better transparency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_fill = {\n",
    "    'last_name': 'Unknown',\n",
    "    'initials': '',\n",
    "    'street_name': 'Unknown',\n",
    "    'house_number': '0',\n",
    "    'postal_code': '0000',\n",
    "    'city': 'Unknown',\n",
    "    'date_of_birth': '',\n",
    "    'account_number': 'Unknown',\n",
    "    'iban': 'Unknown',\n",
    "    'email': ''\n",
    "}\n",
    "df = df.fillna(custom_fill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded. Shape: (7399, 11)\n",
      "\n",
      "ğŸ”‘ Columns and Data Types:\n",
      " last_name         object\n",
      "initials          object\n",
      "street_name       object\n",
      "house_number      object\n",
      "postal_code       object\n",
      "city              object\n",
      "phone_number      object\n",
      "date_of_birth     object\n",
      "account_number    object\n",
      "iban              object\n",
      "email             object\n",
      "dtype: object\n",
      "\n",
      "ğŸ“Š First 5 records:\n",
      "      last_name initials               street_name house_number postal_code  \\\n",
      "0       Jacobs       C.              Gasmeterlaan          247        9000   \n",
      "1        Dries       K.              Groningenlei           15        2550   \n",
      "2    Vermeulen     KURT            Schongaustraat            7        9100   \n",
      "3     Oirschot       L.            Ertbrandstraat          187        2950   \n",
      "4  Compernolle       R.  Albrecht rodenbachstraat            4        8730   \n",
      "\n",
      "                   city phone_number date_of_birth account_number  \\\n",
      "0                  Gent  475644230.0    24/12/1966     1462596514   \n",
      "1               Kontich   32899040.0           NaN   860000000000   \n",
      "2          Sint-niklaas   32966602.0    13/08/1965   737000000000   \n",
      "3  Kapellen (antwerpen)   36052791.0    25/02/1950   733000000000   \n",
      "4               Beernem   50781034.0           NaN    63461819055   \n",
      "\n",
      "               iban                             email  \n",
      "0  BE94001462596514  christian22christian@hotmail.com  \n",
      "1  BE58860111889579       k_van_den_dries@hotmail.com  \n",
      "2  BE70737015498825         kurt.vermeulen1@skynet.be  \n",
      "3  BE42733156017254             gido.imbert@skynet.be  \n",
      "4  BE31063461819055    rechina.compernolle@telenet.be  \n",
      "\n",
      "ğŸ§¹ Missing Values per Column:\n",
      " last_name            4\n",
      "initials            46\n",
      "street_name          0\n",
      "house_number        11\n",
      "postal_code         10\n",
      "city                 0\n",
      "phone_number        11\n",
      "date_of_birth     2982\n",
      "account_number     219\n",
      "iban                 0\n",
      "email                7\n",
      "dtype: int64\n",
      "\n",
      "âœ… Total Missing Values (should be 0 if fully cleaned): 3290\n",
      "\n",
      "ğŸ” Distinct Counts per Column:\n",
      "last_name: 4663 unique values\n",
      "initials: 1274 unique values\n",
      "street_name: 5068 unique values\n",
      "house_number: 476 unique values\n",
      "postal_code: 562 unique values\n",
      "city: 1656 unique values\n",
      "phone_number: 6677 unique values\n",
      "date_of_birth: 3316 unique values\n",
      "account_number: 2713 unique values\n",
      "iban: 6662 unique values\n",
      "email: 6573 unique values\n",
      "\n",
      "ğŸ” Checking for duplicates on 'iban' and 'account_number'...\n",
      "âš ï¸ Duplicate IBAN count: 1463\n",
      "âš ï¸ Duplicate Account Number count: 5103\n",
      "\n",
      "ğŸ“Š Quick Stats for House Number, Postal Code:\n",
      "       house_number postal_code\n",
      "count          7388        7389\n",
      "unique          476         562\n",
      "top               1        9000\n",
      "freq            204         123\n",
      "\n",
      "ğŸ—“ï¸ Sample of Date of Birth values:\n",
      "0     24/12/1966\n",
      "2     13/08/1965\n",
      "3     25/02/1950\n",
      "5     15/09/1967\n",
      "6     25/07/1968\n",
      "7     26/09/1974\n",
      "10    23/10/1988\n",
      "13    15/11/1963\n",
      "16    15/02/1953\n",
      "17    22/02/1979\n",
      "Name: date_of_birth, dtype: object\n",
      "\n",
      "âœ… Example of cleaned rows:\n",
      "     last_name initials            street_name house_number postal_code  \\\n",
      "2473  Van Hoof       M.  Pastoormensaertstraat            9        2340   \n",
      "6731  Naeyaert       T.              Schatting           64        8210   \n",
      "2847  Brangers        M                  Melde           23        2930   \n",
      "169      Theys    BRIAN                Vlierke            5        1820   \n",
      "2036     Herpe    ANNIE       Emiel claeyslaan           31        9050   \n",
      "\n",
      "                city phone_number date_of_birth account_number  \\\n",
      "2473          Beerse   14620720.0    18/06/1963   646000000000   \n",
      "6731        Zedelgem  498812762.0    18/04/1984     1359759841   \n",
      "2847      Brasschaat   36513194.0           NaN     1364792626   \n",
      "169   Steenokkerzeel  477654642.0    28/08/1987   230000000000   \n",
      "2036      Gentbrugge   92313930.0    25/02/1964   737000000000   \n",
      "\n",
      "                  iban                         email  \n",
      "2473  BE92646028839023    nancyberckvens@hotmail.com  \n",
      "6731  BE88001359759841           tnaeyaert@gmail.com  \n",
      "2847  BE59001364792626     marcelabrangers@skynet.be  \n",
      "169   BE76230099238595          briant1712@gmail.com  \n",
      "2036  BE10737446128204  philipe.van.herpe@telenet.be  \n",
      "\n",
      "ğŸš€ Dataset ready for stakeholder handoff and ingestion!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load final cleaned dataset ===\n",
    "final_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv'\n",
    "df = pd.read_csv(final_path, dtype=str)  # Load as string to avoid formatting issues\n",
    "\n",
    "print(\"âœ… Dataset loaded. Shape:\", df.shape)\n",
    "print(\"\\nğŸ”‘ Columns and Data Types:\\n\", df.dtypes)\n",
    "print(\"\\nğŸ“Š First 5 records:\\n\", df.head())\n",
    "\n",
    "# === 1. Check for Missing Values ===\n",
    "missing_summary = df.isnull().sum()\n",
    "print(\"\\nğŸ§¹ Missing Values per Column:\\n\", missing_summary)\n",
    "print(\"\\nâœ… Total Missing Values (should be 0 if fully cleaned):\", missing_summary.sum())\n",
    "\n",
    "# === 2. Unique & Distinct Values per Column ===\n",
    "print(\"\\nğŸ” Distinct Counts per Column:\")\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
    "\n",
    "# === 3. Duplicates Check on Key Fields (IBAN, Account Number) ===\n",
    "print(\"\\nğŸ” Checking for duplicates on 'iban' and 'account_number'...\")\n",
    "duplicate_iban = df[df.duplicated(subset=['iban'], keep=False)]\n",
    "duplicate_account = df[df.duplicated(subset=['account_number'], keep=False)]\n",
    "\n",
    "print(f\"âš ï¸ Duplicate IBAN count: {len(duplicate_iban)}\")\n",
    "print(f\"âš ï¸ Duplicate Account Number count: {len(duplicate_account)}\")\n",
    "\n",
    "# Optional: Export duplicates for review\n",
    "duplicate_iban.to_csv(r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\duplicates_iban.csv', index=False)\n",
    "duplicate_account.to_csv(r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\duplicates_account_number.csv', index=False)\n",
    "\n",
    "# === 4. Statistical Overview for Numeric/Important Fields ===\n",
    "print(\"\\nğŸ“Š Quick Stats for House Number, Postal Code:\")\n",
    "print(df[['house_number', 'postal_code']].describe())\n",
    "\n",
    "# === 5. Review Date of Birth Formatting ===\n",
    "print(\"\\nğŸ—“ï¸ Sample of Date of Birth values:\")\n",
    "print(df['date_of_birth'].dropna().head(10))  # Show samples of non-empty\n",
    "\n",
    "# === 6. Example of Cleaned Records for Presentation ===\n",
    "print(\"\\nâœ… Example of cleaned rows:\")\n",
    "print(df.sample(5, random_state=42))  # Random clean sample for review\n",
    "\n",
    "print(\"\\nğŸš€ Dataset ready for stakeholder handoff and ingestion!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Final cleaned dataset saved successfully at: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv\n",
      "âœ… Final Dataset Shape: (6788, 11)\n",
      "\n",
      "ğŸ“Š Sample of final cleaned data:\n",
      "      last_name initials               street_name house_number postal_code  \\\n",
      "0       Jacobs       C.              Gasmeterlaan          247        9000   \n",
      "1        Dries       K.              Groningenlei           15        2550   \n",
      "2    Vermeulen     KURT            Schongaustraat            7        9100   \n",
      "3     Oirschot       L.            Ertbrandstraat          187        2950   \n",
      "4  Compernolle       R.  Albrecht rodenbachstraat            4        8730   \n",
      "\n",
      "                   city phone_number date_of_birth account_number  \\\n",
      "0                  Gent  475644230.0    24/12/1966     1462596514   \n",
      "1               Kontich   32899040.0                 860000000000   \n",
      "2          Sint-niklaas   32966602.0    13/08/1965   737000000000   \n",
      "3  Kapellen (antwerpen)   36052791.0    25/02/1950   733000000000   \n",
      "4               Beernem   50781034.0                  63461819055   \n",
      "\n",
      "               iban                             email  \n",
      "0  BE94001462596514  christian22christian@hotmail.com  \n",
      "1  BE58860111889579       k_van_den_dries@hotmail.com  \n",
      "2  BE70737015498825         kurt.vermeulen1@skynet.be  \n",
      "3  BE42733156017254             gido.imbert@skynet.be  \n",
      "4  BE31063461819055    rechina.compernolle@telenet.be  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_data(df):\n",
    "    # âœ… Drop duplicate rows across all columns\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # âœ… Replace missing values with blanks for all key fields\n",
    "    df = df.fillna({\n",
    "        'last_name': \"\",\n",
    "        'initials': \"\",\n",
    "        'street_name': \"\",\n",
    "        'house_number': \"\",\n",
    "        'postal_code': \"\",\n",
    "        'city': \"\",\n",
    "        'date_of_birth': \"\",\n",
    "        'account_number': \"\",\n",
    "        'iban': \"\",\n",
    "        'email': \"\"\n",
    "    })\n",
    "\n",
    "    # âœ… Drop rows with missing phone numbers (critical identifier)\n",
    "    df = df.dropna(subset=['phone_number'])\n",
    "\n",
    "    # âœ… Trim leading and trailing whitespace from key text fields\n",
    "    columns_to_trim = ['last_name', 'initials', 'street_name', 'house_number',\n",
    "                       'postal_code', 'city', 'date_of_birth', 'account_number',\n",
    "                       'iban', 'email']\n",
    "    for col in columns_to_trim:\n",
    "        df[col] = df[col].str.strip()\n",
    "\n",
    "    # âœ… Capitalize important text columns for consistency\n",
    "    df['last_name'] = df['last_name'].str.capitalize()\n",
    "    df['street_name'] = df['street_name'].str.capitalize()\n",
    "    df['city'] = df['city'].str.capitalize()\n",
    "\n",
    "    return df\n",
    "\n",
    "# âœ… Load dataset safely (without pyarrow)\n",
    "df = pd.read_csv(r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv', dtype=str)\n",
    "\n",
    "# âœ… Apply cleaning process\n",
    "df_clean = clean_data(df.copy())\n",
    "\n",
    "# âœ… Save cleaned dataset back to same file path (overwrite old version)\n",
    "final_output_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv'\n",
    "df_clean.to_csv(final_output_path, index=False)\n",
    "\n",
    "# âœ… Final confirmations\n",
    "print(f\"ğŸš€ Final cleaned dataset saved successfully at: {final_output_path}\")\n",
    "print(f\"âœ… Final Dataset Shape: {df_clean.shape}\")\n",
    "print(\"\\nğŸ“Š Sample of final cleaned data:\\n\", df_clean.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Duplicate IBAN count: 257\n",
      "âš ï¸ Duplicate Account Number count: 4284\n"
     ]
    }
   ],
   "source": [
    "df_clean.isnull().sum()\n",
    "df_clean.nunique()\n",
    "df_clean.dtypes     \n",
    "\n",
    "# Duplicates in IBAN\n",
    "duplicate_iban = df_clean[df_clean.duplicated('iban', keep=False)]\n",
    "print(f\"âš ï¸ Duplicate IBAN count: {len(duplicate_iban)}\")\n",
    "\n",
    "# Duplicates in account_number\n",
    "duplicate_account = df_clean[df_clean.duplicated('account_number', keep=False)]\n",
    "print(f\"âš ï¸ Duplicate Account Number count: {len(duplicate_account)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded. Shape: (6788, 11)\n",
      "âš ï¸ Duplicate IBANs detected: 132\n",
      "âš ï¸ Duplicate Account Numbers detected: 4077\n",
      "ğŸ—‘ï¸ Total rows to move to garbage file: 4085\n",
      "âœ… Final cleaned dataset shape (after removing dups): (2703, 11)\n",
      "ğŸ’¾ Final clean dataset saved at: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final_review.csv\n",
      "ğŸ’¾ Garbage data (duplicates) saved at: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv\n",
      "\n",
      "ğŸ“Š Cleaning Summary:\n",
      "Original dataset shape: (6788, 11)\n",
      "Duplicates moved to garbage: 4085\n",
      "Final dataset shape: (2703, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# âœ… Load the current cleaned dataset\n",
    "file_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv'\n",
    "df = pd.read_csv(file_path, dtype=str)\n",
    "print(\"âœ… Dataset loaded. Shape:\", df.shape)\n",
    "\n",
    "# =============================\n",
    "# Step 1: Detect Duplicates\n",
    "# =============================\n",
    "\n",
    "# Find duplicate IBAN rows (excluding first occurrence)\n",
    "duplicate_iban = df[df.duplicated('iban', keep='first')]\n",
    "print(f\"âš ï¸ Duplicate IBANs detected: {len(duplicate_iban)}\")\n",
    "\n",
    "# Find duplicate Account Number rows (excluding first occurrence)\n",
    "duplicate_account = df[df.duplicated('account_number', keep='first')]\n",
    "print(f\"âš ï¸ Duplicate Account Numbers detected: {len(duplicate_account)}\")\n",
    "\n",
    "# =============================\n",
    "# Step 2: Combine duplicates\n",
    "# =============================\n",
    "# Combine all detected duplicates into one garbage dataset\n",
    "garbage_data = pd.concat([duplicate_iban, duplicate_account]).drop_duplicates()\n",
    "print(f\"ğŸ—‘ï¸ Total rows to move to garbage file: {len(garbage_data)}\")\n",
    "\n",
    "# =============================\n",
    "# Step 3: Remove duplicates from clean dataset\n",
    "# =============================\n",
    "# Remove all these duplicates from original dataframe\n",
    "df_clean = df.drop(garbage_data.index).reset_index(drop=True)\n",
    "print(f\"âœ… Final cleaned dataset shape (after removing dups): {df_clean.shape}\")\n",
    "\n",
    "# =============================\n",
    "# Step 4: Save cleaned and garbage data\n",
    "# =============================\n",
    "\n",
    "# Save clean dataset back for final review\n",
    "clean_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final_review.csv'\n",
    "df_clean.to_csv(clean_path, index=False)\n",
    "print(f\"ğŸ’¾ Final clean dataset saved at: {clean_path}\")\n",
    "\n",
    "# Save garbage (duplicates) data\n",
    "garbage_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv'\n",
    "garbage_data.to_csv(garbage_path, index=False)\n",
    "print(f\"ğŸ’¾ Garbage data (duplicates) saved at: {garbage_path}\")\n",
    "\n",
    "# =============================\n",
    "# Step 5: Final Summary\n",
    "# =============================\n",
    "print(\"\\nğŸ“Š Cleaning Summary:\")\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Duplicates moved to garbage: {len(garbage_data)}\")\n",
    "print(f\"Final dataset shape: {df_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Final phone number fix applied. Dataset is now fully clean and saved.\n",
      "0    475644230\n",
      "1     32899040\n",
      "2     32966602\n",
      "3     36052791\n",
      "4     50781034\n",
      "5    472453099\n",
      "6    475391350\n",
      "7    476075682\n",
      "8    476385716\n",
      "9    478419735\n",
      "Name: phone_number, dtype: object\n",
      "0    475644230\n",
      "1     32899040\n",
      "2     32966602\n",
      "3     36052791\n",
      "4     50781034\n",
      "5    472453099\n",
      "6    475391350\n",
      "7    476075682\n",
      "8    476385716\n",
      "9    478419735\n",
      "Name: phone_number, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the final cleaned dataset\n",
    "df = pd.read_csv(r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv', dtype=str)\n",
    "\n",
    "# âœ… Fix phone_number by removing '.0' and ensuring it's a string\n",
    "df['phone_number'] = df['phone_number'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "\n",
    "# âœ… Save the fixed dataset back to the same location (overwrite)\n",
    "df.to_csv(r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv', index=False)\n",
    "\n",
    "print(\"ğŸš€ Final phone number fix applied. Dataset is now fully clean and saved.\")\n",
    "print(df['phone_number'].head(10))  # Quick check\n",
    "# Load the dataset again for verification\n",
    "df = pd.read_csv(r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv', dtype=str)\n",
    "\n",
    "# Preview first 10 rows of phone_number to verify fix\n",
    "print(df['phone_number'].head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "belgium_bank_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
