{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Belgium Bank Dataset Cleaning and Preparation Pipeline\n",
    "\n",
    "## üìä Project Overview\n",
    "\n",
    "This notebook contains a professional data cleaning and preparation pipeline for the **Belgium Bank Dataset**, with the goal of transforming raw bank customer data into a structured, consistent, and analysis-ready format. The steps are fully documented for transparency and reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "## üîë Objectives:\n",
    "- Load and inspect the raw dataset.\n",
    "- Rename and translate columns to English.\n",
    "- Detect and handle missing or invalid values.\n",
    "- Standardize and normalize formats (e.g., IBAN, birth dates).\n",
    "- Create a clean output dataset ready for analysis or machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Code Block 1: Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Optional: For regular expressions (Pandas uses regex internally but can import if needed)\n",
    "import re\n",
    "\n",
    "\n",
    "# ‚öôÔ∏è Configuration for visualization\n",
    "pd.set_option('display.max_columns', None)  # Show all columns in output\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 1: Dataset Loading with Encoding Handling\n",
    "\n",
    "In this step:\n",
    "- We attempt to load the raw Belgium Bank dataset.\n",
    "- Since datasets from Europe may contain special characters, we handle potential encoding issues.\n",
    "- First, we try UTF-8 (standard), but if that fails, we fallback to Latin-1 encoding.\n",
    "\n",
    "Below, we also preview the first 5 rows to confirm that data is loaded properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è UTF-8 failed. Dataset loaded successfully using Latin-1 encoding.\n",
      "\n",
      "üîç Preview of first 5 rows:\n",
      "  geslacht   achternaam voorletter tussenvoegsel                straatnaam  \\\n",
      "0      Dhr       Jacobs         C.           NaN              Gasmeterlaan   \n",
      "1      NaN        Dries         K.       van den              Groningenlei   \n",
      "2        M    Vermeulen       KURT           NaN            Schongaustraat   \n",
      "3        V     Oirschot         L.           van            Ertbrandstraat   \n",
      "4     Mevr  Compernolle         R.           NaN  Albrecht rodenbachstraat   \n",
      "\n",
      "  huisnummer toevoeging postcode            woonplaats  telefoonnummer  \\\n",
      "0        247        NaN     9000                  Gent     475644230.0   \n",
      "1         15        NaN     2550               Kontich      32899040.0   \n",
      "2          7        NaN     9100          Sint-niklaas      32966602.0   \n",
      "3        187      bus 1     2950  Kapellen (antwerpen)      36052791.0   \n",
      "4          4        NaN     8730               Beernem      50781034.0   \n",
      "\n",
      "  geboortedatum    rekeningnummer                 iban  \\\n",
      "0    24-12-1966    1462596514      BE94 0014 6259 6514   \n",
      "1    06/09/1987  860111889579      BE58 8601 1188 9579   \n",
      "2    13-08-1965  737015498825      BE70 7370 1549 8825   \n",
      "3    25-02-1950  733156017254      BE42 7331 5601 7254   \n",
      "4    04/08/1951   63461819055      BE31 0634 6181 9055   \n",
      "\n",
      "                              email         bic  \n",
      "0  christian22christian@hotmail.com  GEBA BE BB  \n",
      "1       k_van_den_dries@hotmail.com         NaN  \n",
      "2         kurt.vermeulen1@skynet.be         NaN  \n",
      "3             gido.imbert@skynet.be  KRED BE BB  \n",
      "4    rechina.compernolle@telenet.be  GKCC BE BB  \n"
     ]
    }
   ],
   "source": [
    "# üì• Load dataset from raw_data folder with proper encoding handling\n",
    "file_path = '../raw_data/Belgium-Iban.csv'  # Adjust path if necessary\n",
    "\n",
    "# Attempt to read with utf-8, if it fails, fallback to 'latin-1'\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    print(\"‚úÖ Dataset loaded successfully with UTF-8 encoding.\")\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(file_path, encoding='latin-1')\n",
    "    print(\"‚ö†Ô∏è UTF-8 failed. Dataset loaded successfully using Latin-1 encoding.\")\n",
    "\n",
    "# üßê Preview first few rows to confirm data load\n",
    "print(\"\\nüîç Preview of first 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Step 2: Rename Columns to English\n",
    "\n",
    "To ensure our dataset is globally accessible and easily understandable by international stakeholders, we translate all column names from Dutch to English.\n",
    "\n",
    "### Renamed Columns:\n",
    "- gender\n",
    "- last_name\n",
    "- initials\n",
    "- infix\n",
    "- street_name\n",
    "- house_number\n",
    "- addition\n",
    "- postal_code\n",
    "- city\n",
    "- phone_number\n",
    "- date_of_birth\n",
    "- account_number\n",
    "- iban\n",
    "- email\n",
    "- bic\n",
    "\n",
    "Below is the preview of the renamed dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Columns after renaming to English:\n",
      "['gender', 'last_name', 'initials', 'infix', 'street_name', 'house_number', 'addition', 'postal_code', 'city', 'phone_number', 'date_of_birth', 'account_number', 'iban', 'email', 'bic']\n",
      "\n",
      "üîç Preview of data after renaming columns:\n",
      "  gender    last_name initials    infix               street_name  \\\n",
      "0    Dhr       Jacobs       C.      NaN              Gasmeterlaan   \n",
      "1    NaN        Dries       K.  van den              Groningenlei   \n",
      "2      M    Vermeulen     KURT      NaN            Schongaustraat   \n",
      "3      V     Oirschot       L.      van            Ertbrandstraat   \n",
      "4   Mevr  Compernolle       R.      NaN  Albrecht rodenbachstraat   \n",
      "\n",
      "  house_number addition postal_code                  city  phone_number  \\\n",
      "0          247      NaN        9000                  Gent   475644230.0   \n",
      "1           15      NaN        2550               Kontich    32899040.0   \n",
      "2            7      NaN        9100          Sint-niklaas    32966602.0   \n",
      "3          187    bus 1        2950  Kapellen (antwerpen)    36052791.0   \n",
      "4            4      NaN        8730               Beernem    50781034.0   \n",
      "\n",
      "  date_of_birth    account_number                 iban  \\\n",
      "0    24-12-1966    1462596514      BE94 0014 6259 6514   \n",
      "1    06/09/1987  860111889579      BE58 8601 1188 9579   \n",
      "2    13-08-1965  737015498825      BE70 7370 1549 8825   \n",
      "3    25-02-1950  733156017254      BE42 7331 5601 7254   \n",
      "4    04/08/1951   63461819055      BE31 0634 6181 9055   \n",
      "\n",
      "                              email         bic  \n",
      "0  christian22christian@hotmail.com  GEBA BE BB  \n",
      "1       k_van_den_dries@hotmail.com         NaN  \n",
      "2         kurt.vermeulen1@skynet.be         NaN  \n",
      "3             gido.imbert@skynet.be  KRED BE BB  \n",
      "4    rechina.compernolle@telenet.be  GKCC BE BB  \n"
     ]
    }
   ],
   "source": [
    "# üè∑Ô∏è Step 2: Renaming Columns to English and Standardized Format\n",
    "\n",
    "# Mapping of Dutch to English column names\n",
    "column_rename_map = {\n",
    "    'geslacht': 'gender',\n",
    "    'achternaam': 'last_name',\n",
    "    'voorletter': 'initials',\n",
    "    'tussenvoegsel': 'infix',\n",
    "    'straatnaam': 'street_name',\n",
    "    'huisnummer': 'house_number',\n",
    "    'toevoeging': 'addition',\n",
    "    'postcode': 'postal_code',\n",
    "    'woonplaats': 'city',\n",
    "    'telefoonnummer': 'phone_number',\n",
    "    'geboortedatum': 'date_of_birth',\n",
    "    'rekeningnummer': 'account_number',\n",
    "    'iban': 'iban',\n",
    "    'email': 'email',\n",
    "    'bic': 'bic'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "df.rename(columns=column_rename_map, inplace=True)\n",
    "\n",
    "# ‚úÖ Print renamed columns to verify\n",
    "print(\"\\n‚úÖ Columns after renaming to English:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# üîç Show first 5 rows to confirm changes\n",
    "print(\"\\nüîç Preview of data after renaming columns:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 3: Data Types Standardization & Initial Cleaning\n",
    "üéØ Goal for this Step:\n",
    "Convert columns to proper data types (numbers, dates).\n",
    "Standardize formats (remove spaces, fix IBAN, phone numbers).\n",
    "Prepare data for deeper analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Code Block with Print Statements and Explanations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Starting data type standardization and cleaning process...\n",
      "\n",
      "üîπ Converted 'house_number' to string.\n",
      "üîπ Converted 'phone_number' and 'account_number' to string and cleaned decimals.\n",
      "üîπ Cleaned IBAN numbers by removing spaces.\n",
      "üîπ Converted 'date_of_birth' to datetime format (NaT if invalid).\n",
      "üîπ Converted 'postal_code' to string and stripped whitespace.\n",
      "üîπ Stripped whitespace from all text columns.\n",
      "\n",
      "üîç Data types after standardization:\n",
      " gender                    object\n",
      "last_name                 object\n",
      "initials                  object\n",
      "infix                     object\n",
      "street_name               object\n",
      "house_number              object\n",
      "addition                  object\n",
      "postal_code               object\n",
      "city                      object\n",
      "phone_number              object\n",
      "date_of_birth     datetime64[ns]\n",
      "account_number            object\n",
      "iban                      object\n",
      "email                     object\n",
      "bic                       object\n",
      "dtype: object\n",
      "\n",
      "üîç Preview of cleaned data:\n",
      "   gender    last_name initials    infix               street_name  \\\n",
      "0    Dhr       Jacobs       C.      NaN              Gasmeterlaan   \n",
      "1    NaN        Dries       K.  van den              Groningenlei   \n",
      "2      M    Vermeulen     KURT      NaN            Schongaustraat   \n",
      "3      V     Oirschot       L.      van            Ertbrandstraat   \n",
      "4   Mevr  Compernolle       R.      NaN  Albrecht rodenbachstraat   \n",
      "\n",
      "  house_number addition postal_code                  city phone_number  \\\n",
      "0          247      NaN        9000                  Gent    475644230   \n",
      "1           15      NaN        2550               Kontich     32899040   \n",
      "2            7      NaN        9100          Sint-niklaas     32966602   \n",
      "3          187    bus 1        2950  Kapellen (antwerpen)     36052791   \n",
      "4            4      NaN        8730               Beernem     50781034   \n",
      "\n",
      "  date_of_birth    account_number              iban  \\\n",
      "0    1966-12-24    1462596514      BE94001462596514   \n",
      "1           NaT  860111889579      BE58860111889579   \n",
      "2    1965-08-13  737015498825      BE70737015498825   \n",
      "3    1950-02-25  733156017254      BE42733156017254   \n",
      "4           NaT   63461819055      BE31063461819055   \n",
      "\n",
      "                              email         bic  \n",
      "0  christian22christian@hotmail.com  GEBA BE BB  \n",
      "1       k_van_den_dries@hotmail.com         NaN  \n",
      "2         kurt.vermeulen1@skynet.be         NaN  \n",
      "3             gido.imbert@skynet.be  KRED BE BB  \n",
      "4    rechina.compernolle@telenet.be  GKCC BE BB  \n"
     ]
    }
   ],
   "source": [
    "# üìä Step 3: Data Type Standardization and Initial Cleaning\n",
    "\n",
    "print(\"\\n‚úÖ Starting data type standardization and cleaning process...\\n\")\n",
    "\n",
    "# üî¢ Convert 'house_number' to string (since some houses have addition like '12A')\n",
    "df['house_number'] = df['house_number'].astype(str)\n",
    "print(\"üîπ Converted 'house_number' to string.\")\n",
    "\n",
    "# üî¢ Convert 'phone_number' and 'account_number' to string to preserve leading zeros and formatting\n",
    "df['phone_number'] = df['phone_number'].astype(str).str.replace('.0', '', regex=False)\n",
    "df['account_number'] = df['account_number'].astype(str).str.replace('.0', '', regex=False)\n",
    "print(\"üîπ Converted 'phone_number' and 'account_number' to string and cleaned decimals.\")\n",
    "\n",
    "# üßπ Clean 'iban': Remove all spaces for uniform formatting\n",
    "df['iban'] = df['iban'].str.replace(' ', '').str.strip()\n",
    "print(\"üîπ Cleaned IBAN numbers by removing spaces.\")\n",
    "\n",
    "# üóìÔ∏è Standardize 'date_of_birth' to datetime format\n",
    "df['date_of_birth'] = pd.to_datetime(df['date_of_birth'], errors='coerce', dayfirst=True)\n",
    "print(\"üîπ Converted 'date_of_birth' to datetime format (NaT if invalid).\")\n",
    "\n",
    "# ‚úÖ Clean 'postal_code': Make sure it's a string (some postal codes may start with zero)\n",
    "df['postal_code'] = df['postal_code'].astype(str).str.strip()\n",
    "print(\"üîπ Converted 'postal_code' to string and stripped whitespace.\")\n",
    "\n",
    "# üßΩ Strip leading/trailing whitespaces in textual columns (optional but professional)\n",
    "text_columns = ['gender', 'last_name', 'initials', 'infix', 'street_name', 'addition', 'city', 'email', 'bic']\n",
    "df[text_columns] = df[text_columns].apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "print(\"üîπ Stripped whitespace from all text columns.\")\n",
    "\n",
    "# ‚úÖ Final DataFrame Overview\n",
    "print(\"\\nüîç Data types after standardization:\\n\", df.dtypes)\n",
    "print(\"\\nüîç Preview of cleaned data:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Step 4 - Full Notebook Code & Markdown Example:\n",
    "üì¶ Code Block 1: Identifying Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Checking missing values per column:\n",
      "\n",
      "gender             139\n",
      "last_name            4\n",
      "initials            46\n",
      "infix             6283\n",
      "street_name          0\n",
      "house_number         0\n",
      "addition          6264\n",
      "postal_code          0\n",
      "city                 0\n",
      "phone_number         0\n",
      "date_of_birth     2995\n",
      "account_number       0\n",
      "iban                 0\n",
      "email                0\n",
      "bic                886\n",
      "dtype: int64\n",
      "\n",
      "üìä Percentage of missing values per column:\n",
      "\n",
      "gender             1.87\n",
      "last_name          0.05\n",
      "initials           0.62\n",
      "infix             84.59\n",
      "street_name        0.00\n",
      "house_number       0.00\n",
      "addition          84.33\n",
      "postal_code        0.00\n",
      "city               0.00\n",
      "phone_number       0.00\n",
      "date_of_birth     40.32\n",
      "account_number     0.00\n",
      "iban               0.00\n",
      "email              0.00\n",
      "bic               11.93\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# üìä Checking for missing values in each column\n",
    "print(\"üîé Checking missing values per column:\\n\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# üìè Also showing percentage of missingness for stakeholders\n",
    "print(\"\\nüìä Percentage of missing values per column:\\n\")\n",
    "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "print(missing_percent.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 4: Handling Missing Data and Saving Clean & Garbage Files\n",
    "\n",
    "- **No rows or columns were dropped** ‚Äî all missing values were replaced with empty strings ('').\n",
    "- **Two versions** of the dataset have been saved:\n",
    "  - **Garbage Data File** (contains blanks but retains all raw records): `belgium_bank_garbage_data.csv`\n",
    "  - **Clean Data File** (ready for analysis with blanks instead of NaNs): `belgium_bank_clean_data.csv`\n",
    "- This ensures we keep **full transparency and flexibility** for future review and decision-making.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Verifying that all missing values have been filled with blanks (should show 0 for all):\n",
      "\n",
      "gender               0\n",
      "last_name            0\n",
      "initials             0\n",
      "infix                0\n",
      "street_name          0\n",
      "house_number         0\n",
      "addition             0\n",
      "postal_code          0\n",
      "city                 0\n",
      "phone_number         0\n",
      "date_of_birth     2995\n",
      "account_number       0\n",
      "iban                 0\n",
      "email                0\n",
      "bic                  0\n",
      "dtype: int64\n",
      "\n",
      "üíæ Garbage dataset saved successfully at: ../output/belgium_bank_garbage_data.csv\n",
      "üíæ Clean dataset saved successfully at: ../output/belgium_bank_clean_data.csv\n"
     ]
    }
   ],
   "source": [
    "# üõ†Ô∏è Step 4: Handling Missing Data & Saving Both Garbage and Clean Files\n",
    "\n",
    "# ‚úÖ Replacing all missing values with empty strings to preserve all records\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# ‚úÖ Confirming that missing values are handled\n",
    "print(\"\\nüîÑ Verifying that all missing values have been filled with blanks (should show 0 for all):\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# üíæ Save the \"garbage data\" version (with blanks but no removed data)\n",
    "garbage_file_path = '../output/belgium_bank_garbage_data.csv'\n",
    "df.to_csv(garbage_file_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nüíæ Garbage dataset saved successfully at: {garbage_file_path}\")\n",
    "\n",
    "# üíæ Save the \"clean data\" version for analysis\n",
    "clean_file_path = '../output/belgium_bank_clean_data.csv'\n",
    "df.to_csv(clean_file_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"üíæ Clean dataset saved successfully at: {clean_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Data Consistency & Validation\n",
    "\n",
    "In this step, we will focus on **validating critical fields** such as IBAN, BIC, phone numbers, and dates of birth to ensure they follow expected formats. This is essential to maintain high-quality, reliable datasets for analysis and downstream use.\n",
    "\n",
    "### ‚úÖ Fields to Validate:\n",
    "1. **IBAN Numbers** - Correct Belgian IBAN format.\n",
    "2. **Phone Numbers** - Expected length and numeric format.\n",
    "3. **Date of Birth** - Detect invalid/missing dates.\n",
    "4. **BIC Codes** - Proper format and length (typically 8 or 11 characters).\n",
    "5. **Duplicate Checks** - Avoid double entries (e.g., same IBAN or email).\n",
    "\n",
    "Let's start!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned dataset loaded for validation. Number of records: 24\n",
      "    gender last_name initials infix              street_name house_number  \\\n",
      "122    Dhr   Petegem        G   Van         Kunnenbergstraat            8   \n",
      "309   Mevr   Verwimp        F        P.Van Langendonckstraat           19   \n",
      "560      V     Melis       A.               Winterslagstraat          105   \n",
      "\n",
      "    addition postal_code        city phone_number date_of_birth  \\\n",
      "122                 9660      Brakel    495211164    1973-12-17   \n",
      "309                 9050  Gentbrugge     92314605                 \n",
      "560    Bus 1        3600     Centrum    486405695    1966-09-20   \n",
      "\n",
      "       account_number              iban                        email  \\\n",
      "122  780581655863      BE40780581655863      adarma.lieve@telenet.be   \n",
      "309    1105666826      BE59001105666826  florette.verwimp@telenet.be   \n",
      "560    1645777172      BE38001645777172         Melisanita@gmail.com   \n",
      "\n",
      "          bic validation_issues  \n",
      "122  GKCCBEBB                OK  \n",
      "309  GEBABEBB                OK  \n",
      "560  GEBABEBB                OK  \n",
      "‚ö†Ô∏è Found 0 invalid IBAN(s).\n",
      "Empty DataFrame\n",
      "Columns: [iban]\n",
      "Index: []\n",
      "üíæ Invalid IBANs saved to 'output/belgium_bank_invalid_iban.csv'.\n",
      "‚ö†Ô∏è Found 0 invalid phone number(s).\n",
      "Empty DataFrame\n",
      "Columns: [phone_number]\n",
      "Index: []\n",
      "üíæ Invalid phone numbers saved to 'output/belgium_bank_invalid_phone.csv'.\n",
      "‚ö†Ô∏è Found 0 invalid BIC(s).\n",
      "Empty DataFrame\n",
      "Columns: [bic]\n",
      "Index: []\n",
      "üíæ Invalid BICs saved to 'output/belgium_bank_invalid_bic.csv'.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Cleaned dataset loaded for validation\n",
    "print(\"‚úÖ Cleaned dataset loaded for validation. Number of records:\", len(clean_data))\n",
    "print(clean_data.head(3))  # Quick peek\n",
    "\n",
    "# ------------------- IBAN Validation ------------------- #\n",
    "# IBAN must start with 'BE' followed by 14 digits\n",
    "invalid_iban = clean_data[~clean_data['iban'].str.match(r'^BE\\d{14}$')]\n",
    "print(f\"‚ö†Ô∏è Found {len(invalid_iban)} invalid IBAN(s).\")\n",
    "print(invalid_iban[['iban']].head(5))\n",
    "invalid_iban.to_csv('../output/belgium_bank_invalid_iban.csv', index=False)\n",
    "print(\"üíæ Invalid IBANs saved to 'output/belgium_bank_invalid_iban.csv'.\")\n",
    "\n",
    "# ------------------- Phone Number Validation ------------------- #\n",
    "# Ensure column is string and fill blanks\n",
    "clean_data['phone_number'] = clean_data['phone_number'].fillna('').astype(str)\n",
    "\n",
    "# Check for numeric-only, 8-10 digits\n",
    "invalid_phone = clean_data[~clean_data['phone_number'].str.match(r'^\\d{8,10}$')]\n",
    "print(f\"‚ö†Ô∏è Found {len(invalid_phone)} invalid phone number(s).\")\n",
    "print(invalid_phone[['phone_number']].head(5))\n",
    "invalid_phone.to_csv('../output/belgium_bank_invalid_phone.csv', index=False)\n",
    "print(\"üíæ Invalid phone numbers saved to 'output/belgium_bank_invalid_phone.csv'.\")\n",
    "\n",
    "# ------------------- BIC Validation ------------------- #\n",
    "# BIC must be 8 or 11 alphanumeric characters\n",
    "clean_data['bic'] = clean_data['bic'].fillna('').astype(str)  # Ensure string type\n",
    "invalid_bic = clean_data[\n",
    "    (clean_data['bic'] != '') &\n",
    "    (~clean_data['bic'].str.match(r'^[A-Z0-9]{8}([A-Z0-9]{3})?$'))\n",
    "]\n",
    "print(f\"‚ö†Ô∏è Found {len(invalid_bic)} invalid BIC(s).\")\n",
    "print(invalid_bic[['bic']].head(5))\n",
    "invalid_bic.to_csv('../output/belgium_bank_invalid_bic.csv', index=False)\n",
    "print(\"üíæ Invalid BICs saved to 'output/belgium_bank_invalid_bic.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Fix Phone and BIC Issues + Re-run Validations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Found 0 invalid phone number(s) AFTER FIX.\n",
      "Empty DataFrame\n",
      "Columns: [phone_number]\n",
      "Index: []\n",
      "üíæ Invalid phone numbers saved to 'output/belgium_bank_invalid_phone.csv'.\n",
      "‚ö†Ô∏è Found 0 invalid BIC(s) AFTER FIX.\n",
      "Empty DataFrame\n",
      "Columns: [bic]\n",
      "Index: []\n",
      "üíæ Invalid BICs saved to 'output/belgium_bank_invalid_bic.csv'.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Fix phone number: remove decimals and spaces\n",
    "clean_data['phone_number'] = clean_data['phone_number'].fillna('').astype(str).str.replace(r'\\.0$', '', regex=True).str.strip()\n",
    "\n",
    "# ‚úÖ Fix BIC: remove spaces\n",
    "clean_data['bic'] = clean_data['bic'].fillna('').astype(str).str.replace(' ', '').str.strip()\n",
    "\n",
    "# ------------------- Re-run Phone Number Validation ------------------- #\n",
    "invalid_phone = clean_data[~clean_data['phone_number'].str.match(r'^\\d{8,10}$')]\n",
    "print(f\"‚ö†Ô∏è Found {len(invalid_phone)} invalid phone number(s) AFTER FIX.\")\n",
    "print(invalid_phone[['phone_number']].head(5))\n",
    "invalid_phone.to_csv('../output/belgium_bank_invalid_phone.csv', index=False)\n",
    "print(\"üíæ Invalid phone numbers saved to 'output/belgium_bank_invalid_phone.csv'.\")\n",
    "\n",
    "# ------------------- Re-run BIC Validation ------------------- #\n",
    "invalid_bic = clean_data[\n",
    "    (clean_data['bic'] != '') &\n",
    "    (~clean_data['bic'].str.match(r'^[A-Z0-9]{8}([A-Z0-9]{3})?$'))\n",
    "]\n",
    "print(f\"‚ö†Ô∏è Found {len(invalid_bic)} invalid BIC(s) AFTER FIX.\")\n",
    "print(invalid_bic[['bic']].head(5))\n",
    "invalid_bic.to_csv('../output/belgium_bank_invalid_bic.csv', index=False)\n",
    "print(\"üíæ Invalid BICs saved to 'output/belgium_bank_invalid_bic.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Step 5: Final Validation & Correction of Belgium Bank Dataset\n",
    "In this step, we perform **final checks** and corrections on:\n",
    "- **Phone Numbers**: Ensuring correct numeric format, length.\n",
    "- **BIC Codes**: Proper format, length, uppercase without spaces.\n",
    "\n",
    "We'll also re-validate for any remaining issues and save final datasets.\n",
    "\n",
    "**Deliverables:**\n",
    "- `belgium_bank_clean_data_final.csv`: Final cleaned data\n",
    "- `belgium_bank_invalid_phone.csv`: Remaining invalid phone numbers (if any)\n",
    "- `belgium_bank_invalid_bic.csv`: Remaining invalid BIC codes (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Found 0 invalid email(s).\n",
      "Empty DataFrame\n",
      "Columns: [email]\n",
      "Index: []\n",
      "üíæ Invalid emails saved to 'output/belgium_bank_invalid_emails.csv'.\n",
      "‚ö†Ô∏è Found 0 invalid phone number(s) AFTER FIX.\n",
      "Empty DataFrame\n",
      "Columns: [phone_number]\n",
      "Index: []\n",
      "üíæ Invalid phone numbers saved to 'output/belgium_bank_invalid_phone.csv'.\n",
      "‚ö†Ô∏è Found 0 invalid BIC(s) AFTER FIX.\n",
      "Empty DataFrame\n",
      "Columns: [bic]\n",
      "Index: []\n",
      "üíæ Invalid BICs saved to 'output/belgium_bank_invalid_bic.csv'.\n",
      "‚ö†Ô∏è Total invalid IBANs detected: 0\n",
      "üîç Sample of invalid IBANs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>initials</th>\n",
       "      <th>infix</th>\n",
       "      <th>street_name</th>\n",
       "      <th>house_number</th>\n",
       "      <th>addition</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>city</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>account_number</th>\n",
       "      <th>iban</th>\n",
       "      <th>email</th>\n",
       "      <th>bic</th>\n",
       "      <th>validation_issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gender, last_name, initials, infix, street_name, house_number, addition, postal_code, city, phone_number, date_of_birth, account_number, iban, email, bic, validation_issues]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ‚úÖ Ensure phone_number is string and NaNs are empty strings\n",
    "clean_data['phone_number'] = clean_data['phone_number'].fillna('').astype(str)\n",
    "\n",
    "# ‚úÖ Remove non-digit characters\n",
    "clean_data['phone_number'] = clean_data['phone_number'].str.replace(r'\\D', '', regex=True)\n",
    "\n",
    "\n",
    "\n",
    "# Validate email format using regex\n",
    "email_pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
    "invalid_emails = clean_data[~clean_data['email'].str.match(email_pattern, na=False)]\n",
    "\n",
    "print(f\"‚ö†Ô∏è Found {len(invalid_emails)} invalid email(s).\")\n",
    "print(invalid_emails[['email']].head())\n",
    "\n",
    "# Optionally save for review\n",
    "invalid_emails.to_csv('../output/belgium_bank_invalid_emails.csv', index=False)\n",
    "print(\"üíæ Invalid emails saved to 'output/belgium_bank_invalid_emails.csv'.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ‚úÖ Now safely apply regex check for valid 8-10 digit phone numbers\n",
    "invalid_phone = clean_data[~clean_data['phone_number'].str.match(r'^\\d{8,10}$', na=False)]\n",
    "\n",
    "print(f\"‚ö†Ô∏è Found {len(invalid_phone)} invalid phone number(s) AFTER FIX.\")\n",
    "print(invalid_phone[['phone_number']].head())\n",
    "\n",
    "# üíæ Save invalid phone numbers\n",
    "invalid_phone.to_csv('../output/belgium_bank_invalid_phone.csv', index=False)\n",
    "print(\"üíæ Invalid phone numbers saved to 'output/belgium_bank_invalid_phone.csv'.\")\n",
    "\n",
    "# ‚úÖ Fix BICs: ensure string type, fill NaNs, remove spaces, and uppercase\n",
    "clean_data['bic'] = clean_data['bic'].fillna('').astype(str).str.replace(r'\\s+', '', regex=True).str.upper()\n",
    "\n",
    "# ‚úÖ Validate BICs (8 or 11 alphanumeric characters)\n",
    "invalid_bic = clean_data[\n",
    "    (clean_data['bic'] != '') &  # Not empty\n",
    "    (~clean_data['bic'].str.match(r'^[A-Z0-9]{8}([A-Z0-9]{3})?$', na=False))\n",
    "]\n",
    "\n",
    "print(f\"‚ö†Ô∏è Found {len(invalid_bic)} invalid BIC(s) AFTER FIX.\")\n",
    "print(invalid_bic[['bic']].head())\n",
    "\n",
    "# üíæ Save invalid BICs\n",
    "invalid_bic.to_csv('../output/belgium_bank_invalid_bic.csv', index=False)\n",
    "print(\"üíæ Invalid BICs saved to 'output/belgium_bank_invalid_bic.csv'.\")\n",
    "\n",
    "# üìÇ Load Invalid IBAN File\n",
    "invalid_iban_path = '../output/belgium_bank_invalid_iban.csv'\n",
    "invalid_iban = pd.read_csv(invalid_iban_path)\n",
    "\n",
    "# Display summary\n",
    "print(f\"‚ö†Ô∏è Total invalid IBANs detected: {len(invalid_iban)}\")\n",
    "print(\"üîç Sample of invalid IBANs:\")\n",
    "display(invalid_iban.head(10))  # Display top 10 as sample\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Step 5: Full Dataset Inspection & Final Cleaning Actions\n",
    "\n",
    "In this step, we will:\n",
    "\n",
    "1. Inspect data types and value distributions to ensure everything looks consistent.\n",
    "2. Perform validation and cleaning for **email addresses**.\n",
    "3. Perform validation and cleaning for **names** (first and last names, initials).\n",
    "4. Check and handle **duplicate rows** based on critical identifiers.\n",
    "5. Export the fully cleaned dataset for analysis.\n",
    "\n",
    "This step ensures that we **finalize the dataset quality** before moving into analysis and modeling phases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>last_name</th>\n",
       "      <th>initials</th>\n",
       "      <th>infix</th>\n",
       "      <th>street_name</th>\n",
       "      <th>house_number</th>\n",
       "      <th>addition</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>city</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>account_number</th>\n",
       "      <th>iban</th>\n",
       "      <th>email</th>\n",
       "      <th>bic</th>\n",
       "      <th>validation_issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Dhr</td>\n",
       "      <td>Petegem</td>\n",
       "      <td>G</td>\n",
       "      <td>Van</td>\n",
       "      <td>Kunnenbergstraat</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>9660</td>\n",
       "      <td>Brakel</td>\n",
       "      <td>495211164</td>\n",
       "      <td>1973-12-17</td>\n",
       "      <td>780581655863</td>\n",
       "      <td>BE40780581655863</td>\n",
       "      <td>adarma.lieve@telenet.be</td>\n",
       "      <td>GKCCBEBB</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Mevr</td>\n",
       "      <td>Verwimp</td>\n",
       "      <td>F</td>\n",
       "      <td></td>\n",
       "      <td>P.Van Langendonckstraat</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td>9050</td>\n",
       "      <td>Gentbrugge</td>\n",
       "      <td>92314605</td>\n",
       "      <td></td>\n",
       "      <td>1105666826</td>\n",
       "      <td>BE59001105666826</td>\n",
       "      <td>florette.verwimp@telenet.be</td>\n",
       "      <td>GEBABEBB</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>V</td>\n",
       "      <td>Melis</td>\n",
       "      <td>A.</td>\n",
       "      <td></td>\n",
       "      <td>Winterslagstraat</td>\n",
       "      <td>105</td>\n",
       "      <td>Bus 1</td>\n",
       "      <td>3600</td>\n",
       "      <td>Centrum</td>\n",
       "      <td>486405695</td>\n",
       "      <td>1966-09-20</td>\n",
       "      <td>1645777172</td>\n",
       "      <td>BE38001645777172</td>\n",
       "      <td>Melisanita@gmail.com</td>\n",
       "      <td>GEBABEBB</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>Dhr</td>\n",
       "      <td>Bals</td>\n",
       "      <td>P</td>\n",
       "      <td></td>\n",
       "      <td>Vossekotstraat</td>\n",
       "      <td>62</td>\n",
       "      <td></td>\n",
       "      <td>9100</td>\n",
       "      <td>St-Niklaas</td>\n",
       "      <td>478234393</td>\n",
       "      <td>1971-01-16</td>\n",
       "      <td>293056336140</td>\n",
       "      <td>BE02293056336140</td>\n",
       "      <td>bals_peter@telenet.be</td>\n",
       "      <td>GEBABEBB</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>Mevr</td>\n",
       "      <td>Boutens</td>\n",
       "      <td>R</td>\n",
       "      <td></td>\n",
       "      <td>Kortrijkessteenweg</td>\n",
       "      <td>84</td>\n",
       "      <td></td>\n",
       "      <td>9800</td>\n",
       "      <td>Denzie</td>\n",
       "      <td>499159550</td>\n",
       "      <td></td>\n",
       "      <td>63450274439</td>\n",
       "      <td>BE13063450274439</td>\n",
       "      <td>BT.rosita@hotmail.be</td>\n",
       "      <td>GKCCBEBB</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender last_name initials infix              street_name house_number  \\\n",
       "122     Dhr   Petegem        G   Van         Kunnenbergstraat            8   \n",
       "309    Mevr   Verwimp        F        P.Van Langendonckstraat           19   \n",
       "560       V     Melis       A.               Winterslagstraat          105   \n",
       "1568    Dhr      Bals        P                 Vossekotstraat           62   \n",
       "1675   Mevr   Boutens        R             Kortrijkessteenweg           84   \n",
       "\n",
       "     addition postal_code        city phone_number date_of_birth  \\\n",
       "122                  9660      Brakel    495211164    1973-12-17   \n",
       "309                  9050  Gentbrugge     92314605                 \n",
       "560     Bus 1        3600     Centrum    486405695    1966-09-20   \n",
       "1568                 9100  St-Niklaas    478234393    1971-01-16   \n",
       "1675                 9800      Denzie    499159550                 \n",
       "\n",
       "        account_number              iban                        email  \\\n",
       "122   780581655863      BE40780581655863      adarma.lieve@telenet.be   \n",
       "309     1105666826      BE59001105666826  florette.verwimp@telenet.be   \n",
       "560     1645777172      BE38001645777172         Melisanita@gmail.com   \n",
       "1568  293056336140      BE02293056336140        bals_peter@telenet.be   \n",
       "1675   63450274439      BE13063450274439         BT.rosita@hotmail.be   \n",
       "\n",
       "           bic validation_issues  \n",
       "122   GKCCBEBB                OK  \n",
       "309   GEBABEBB                OK  \n",
       "560   GEBABEBB                OK  \n",
       "1568  GEBABEBB                OK  \n",
       "1675  GKCCBEBB                OK  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Data Types:\n",
      "gender               object\n",
      "last_name            object\n",
      "initials             object\n",
      "infix                object\n",
      "street_name          object\n",
      "house_number         object\n",
      "addition             object\n",
      "postal_code          object\n",
      "city                 object\n",
      "phone_number         object\n",
      "date_of_birth        object\n",
      "account_number       object\n",
      "iban                 object\n",
      "email                object\n",
      "bic                  object\n",
      "validation_issues    object\n",
      "dtype: object\n",
      "\n",
      "üî¢ Dataset shape (rows, columns): (24, 16)\n",
      "\n",
      "üìä Checking null counts per column:\n",
      "gender               0\n",
      "last_name            0\n",
      "initials             0\n",
      "infix                0\n",
      "street_name          0\n",
      "house_number         0\n",
      "addition             0\n",
      "postal_code          0\n",
      "city                 0\n",
      "phone_number         0\n",
      "date_of_birth        0\n",
      "account_number       0\n",
      "iban                 0\n",
      "email                0\n",
      "bic                  0\n",
      "validation_issues    0\n",
      "dtype: int64\n",
      "\n",
      "üìä Unique counts in each column:\n",
      "gender                5\n",
      "last_name            23\n",
      "initials             21\n",
      "infix                 4\n",
      "street_name          23\n",
      "house_number         22\n",
      "addition              2\n",
      "postal_code          21\n",
      "city                 21\n",
      "phone_number         23\n",
      "date_of_birth        11\n",
      "account_number       23\n",
      "iban                 23\n",
      "email                23\n",
      "bic                   8\n",
      "validation_issues     1\n",
      "dtype: int64\n",
      "\n",
      "üéØ Checking summary statistics for numeric-looking fields:\n",
      "                  count unique                      top freq\n",
      "gender               24      5                        V    9\n",
      "last_name            24     23                   Helson    2\n",
      "initials             24     21                       C.    2\n",
      "infix                24      4                            21\n",
      "street_name          24     23               Rue Ferrer    2\n",
      "house_number         24     22                       16    2\n",
      "addition             24      2                            23\n",
      "postal_code          24     21                     8500    2\n",
      "city                 24     21                 Kortrijk    2\n",
      "phone_number         24     23                478325760    2\n",
      "date_of_birth        24     11                            14\n",
      "account_number       24     23           1281569959        2\n",
      "iban                 24     23         BE84001281569959    2\n",
      "email                24     23  fannyhelson@hotmail.com    2\n",
      "bic                  24      8                 GKCCBEBB    7\n",
      "validation_issues    24      1                       OK   24\n"
     ]
    }
   ],
   "source": [
    "# üîç Inspect basic information\n",
    "print(\"‚úÖ Dataset Preview:\")\n",
    "display(clean_data.head(5))\n",
    "\n",
    "print(\"\\n‚úÖ Data Types:\")\n",
    "print(clean_data.dtypes)\n",
    "\n",
    "print(\"\\nüî¢ Dataset shape (rows, columns):\", clean_data.shape)\n",
    "\n",
    "print(\"\\nüìä Checking null counts per column:\")\n",
    "print(clean_data.isnull().sum())\n",
    "\n",
    "print(\"\\nüìä Unique counts in each column:\")\n",
    "print(clean_data.nunique())\n",
    "\n",
    "print(\"\\nüéØ Checking summary statistics for numeric-looking fields:\")\n",
    "print(clean_data.describe(include='all').transpose())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Final Code Block with Markdown for Names Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded. Shape: (7428, 15)\n",
      "\n",
      "üîç Preview after name standardization:\n",
      "     last_name initials    infix\n",
      "0       Jacobs       C.         \n",
      "1        Dries       K.  Van Den\n",
      "2    Vermeulen     KURT         \n",
      "3     Oirschot       L.      Van\n",
      "4  Compernolle       R.         \n",
      "5      Taalman       M.         \n",
      "6  Blauwblomme       V.         \n",
      "7  El-Khattabi       R.         \n",
      "8       Jannis       Y.         \n",
      "9     Vlaminck       C.         \n",
      "\n",
      "üíæ Cleaned dataset with fixed names saved to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_with_fixed_names.csv\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# ## ‚ú® Step 1: Standardizing Names (Last Names, Initials, Infix)\n",
    "# - Title-case all last names and infix (e.g., \"van\" to \"Van\")\n",
    "# - Upper-case initials (e.g., \"k.\" to \"K.\")\n",
    "# - Strip extra spaces and handle blanks\n",
    "# ---\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Load the working clean dataset\n",
    "file_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data.csv'\n",
    "df = pd.read_csv(file_path, dtype=str)\n",
    "print(\"‚úÖ Dataset loaded. Shape:\", df.shape)\n",
    "\n",
    "# ‚úÖ Fill NaNs as blanks for consistency\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# ‚úÖ Strip and format names properly\n",
    "df['last_name'] = df['last_name'].str.strip().str.title()  # Title case, strip spaces\n",
    "df['initials'] = df['initials'].str.strip().str.upper()   # Upper case, strip spaces\n",
    "df['infix'] = df['infix'].str.strip().str.title()         # Title case, strip spaces\n",
    "\n",
    "# ‚úÖ Preview to confirm the transformation\n",
    "print(\"\\nüîç Preview after name standardization:\")\n",
    "print(df[['last_name', 'initials', 'infix']].head(10))\n",
    "\n",
    "# ‚úÖ Save updated dataset to a new clean file\n",
    "output_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_with_fixed_names.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nüíæ Cleaned dataset with fixed names saved to: {output_path}\")\n",
    "\n",
    "# ---\n",
    "# ‚úÖ Summary:\n",
    "# - Names properly formatted\n",
    "# - Dataset ready for next steps (email/IBAN/BIC/duplicates)\n",
    "# ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Corrected Approach for Email Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded. Shape: (7428, 15)\n",
      "‚ö†Ô∏è Found 8 invalid email(s).\n",
      "üíæ Invalid email rows saved to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv\n",
      "üíæ Updated clean dataset saved to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_emails_valid.csv\n",
      "\n",
      "üìä Email Cleaning Summary:\n",
      "Total records retained: 7428\n",
      "Invalid emails moved to garbage file: 8\n",
      "üöÄ Ready for next cleaning step (phone, BIC, IBAN)!\n"
     ]
    }
   ],
   "source": [
    "# üìå Step 2: Email Validation (Retain all rows, separate invalid emails)\n",
    "\n",
    "\n",
    "# üîΩ Load dataset with fixed names\n",
    "file_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_with_fixed_names.csv'\n",
    "df = pd.read_csv(file_path, dtype=str)\n",
    "print(f\"‚úÖ Dataset loaded. Shape: {df.shape}\")\n",
    "\n",
    "# üßΩ Fill blanks and strip whitespaces for safety\n",
    "df['email'] = df['email'].fillna('').str.strip()\n",
    "\n",
    "# ‚úÖ Email validation pattern\n",
    "email_pattern = r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\"\n",
    "\n",
    "# üîç Detect invalid emails\n",
    "invalid_email_mask = ~df['email'].str.match(email_pattern, na=False)\n",
    "invalid_emails_df = df[invalid_email_mask].copy()\n",
    "print(f\"‚ö†Ô∏è Found {len(invalid_emails_df)} invalid email(s).\")\n",
    "\n",
    "# üíæ Save rows with invalid emails to garbage file for review\n",
    "garbage_output_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv'\n",
    "invalid_emails_df.to_csv(garbage_output_path, index=False)\n",
    "print(f\"üíæ Invalid email rows saved to: {garbage_output_path}\")\n",
    "\n",
    "# üßπ Blank out invalid emails in main dataset (retain row)\n",
    "df.loc[invalid_email_mask, 'email'] = ''\n",
    "\n",
    "# üíæ Save updated clean dataset (emails cleaned)\n",
    "clean_emails_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_emails_valid.csv'\n",
    "df.to_csv(clean_emails_path, index=False)\n",
    "print(f\"üíæ Updated clean dataset saved to: {clean_emails_path}\")\n",
    "\n",
    "# ‚úÖ Summary\n",
    "print(\"\\nüìä Email Cleaning Summary:\")\n",
    "print(f\"Total records retained: {len(df)}\")\n",
    "print(f\"Invalid emails moved to garbage file: {len(invalid_emails_df)}\")\n",
    "print(\"üöÄ Ready for next cleaning step (phone, BIC, IBAN)!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---\n",
    "# ## üìû Phone Number Validation & Cleanup\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded. Shape: (7428, 15)\n",
      "‚ö†Ô∏è Found 11 invalid phone number(s).\n",
      "     phone_number\n",
      "144           NaN\n",
      "335   5.37014e+17\n",
      "1581            3\n",
      "2820          NaN\n",
      "2821          NaN\n",
      "üíæ Invalid phone numbers added to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv\n",
      "üíæ Updated clean dataset saved to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_phones_valid.csv\n",
      "\n",
      "üìä Phone Number Cleaning Summary:\n",
      "Total records retained: 7428\n",
      "Invalid phone numbers moved to garbage file: 11\n",
      "üöÄ Ready for next cleaning step (BIC or IBAN)!\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# ## üìû Phone Number Validation & Cleanup\n",
    "# ---\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Load the current working clean dataset\n",
    "file_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_emails_valid.csv'\n",
    "df = pd.read_csv(file_path, dtype=str)\n",
    "print(\"‚úÖ Dataset loaded. Shape:\", df.shape)\n",
    "\n",
    "# ‚úÖ Define phone number validation pattern (8 to 10 digits only)\n",
    "phone_pattern = r\"^\\d{8,10}$\"\n",
    "\n",
    "# ========================\n",
    "# STEP 1: Find Invalid Phones\n",
    "# ========================\n",
    "invalid_phone_mask = ~df['phone_number'].str.match(phone_pattern, na=False)\n",
    "invalid_phones = df[invalid_phone_mask].copy()\n",
    "\n",
    "print(f\"‚ö†Ô∏è Found {len(invalid_phones)} invalid phone number(s).\")\n",
    "print(invalid_phones[['phone_number']].head())\n",
    "\n",
    "# ========================\n",
    "# STEP 2: Add Invalid Phones to Garbage File\n",
    "# ========================\n",
    "# Load existing garbage file to append\n",
    "garbage_file_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv'\n",
    "try:\n",
    "    garbage_df = pd.read_csv(garbage_file_path, dtype=str)\n",
    "except FileNotFoundError:\n",
    "    garbage_df = pd.DataFrame()  # Create empty DataFrame if doesn't exist yet\n",
    "\n",
    "# Append new invalid phones\n",
    "updated_garbage_df = pd.concat([garbage_df, invalid_phones], ignore_index=True)\n",
    "\n",
    "# Save updated garbage\n",
    "updated_garbage_df.to_csv(garbage_file_path, index=False)\n",
    "print(f\"üíæ Invalid phone numbers added to: {garbage_file_path}\")\n",
    "\n",
    "# ========================\n",
    "# STEP 3: Blank Invalid Phone Numbers in Clean Dataset\n",
    "# ========================\n",
    "df.loc[invalid_phone_mask, 'phone_number'] = ''\n",
    "\n",
    "# ========================\n",
    "# STEP 4: Save Updated Clean Dataset\n",
    "# ========================\n",
    "clean_output_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_phones_valid.csv'\n",
    "df.to_csv(clean_output_path, index=False)\n",
    "print(f\"üíæ Updated clean dataset saved to: {clean_output_path}\")\n",
    "\n",
    "# ========================\n",
    "# ‚úÖ STEP 5: Summary\n",
    "# ========================\n",
    "print(\"\\nüìä Phone Number Cleaning Summary:\")\n",
    "print(\"Total records retained:\", len(df))\n",
    "print(\"Invalid phone numbers moved to garbage file:\", len(invalid_phones))\n",
    "print(\"üöÄ Ready for next cleaning step (BIC or IBAN)!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Step: BIC (Bank Identifier Code) Validation & Cleanup\n",
    "üìå Goal:\n",
    "Check that all BIC values follow correct format:\n",
    "8 or 11 characters, uppercase, letters and/or digits.\n",
    "Invalid BICs ‚û°Ô∏è moved to garbage file AND replaced with blank in the clean dataset (NO row deletions!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Final Consolidation Code Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded dataset for finalization: (7428, 15)\n",
      "üóëÔ∏è Dropped 'bic' column.\n",
      "üíæ Final clean dataset saved to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final.csv\n",
      "üíæ All garbage data consolidated to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load last cleaned dataset\n",
    "final_clean_file = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_phones_valid.csv'\n",
    "df = pd.read_csv(final_clean_file, dtype=str)\n",
    "\n",
    "print(\"‚úÖ Loaded dataset for finalization:\", df.shape)\n",
    "\n",
    "# Drop BIC (based on previous decision)\n",
    "if 'bic' in df.columns:\n",
    "    df.drop(columns=['bic'], inplace=True)\n",
    "    print(\"üóëÔ∏è Dropped 'bic' column.\")\n",
    "\n",
    "# Final formatting check (strip whitespace)\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].fillna('').astype(str).str.strip()\n",
    "\n",
    "# Save final clean file\n",
    "final_output_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final.csv'\n",
    "df.to_csv(final_output_path, index=False)\n",
    "print(f\"üíæ Final clean dataset saved to: {final_output_path}\")\n",
    "\n",
    "# (Optional) Combine all garbage files into one\n",
    "garbage_files = [\n",
    "    r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv',\n",
    "    # Add paths to other specific garbage datasets if not yet combined\n",
    "]\n",
    "garbage_dfs = [pd.read_csv(file, dtype=str) for file in garbage_files]\n",
    "combined_garbage = pd.concat(garbage_dfs, ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Save combined garbage data\n",
    "combined_garbage_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv'\n",
    "combined_garbage.to_csv(combined_garbage_path, index=False)\n",
    "print(f\"üíæ All garbage data consolidated to: {combined_garbage_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Here‚Äôs the code to execute this step properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded. Shape: (7428, 14)\n",
      "‚ö†Ô∏è Found 29 invalid IBAN(s).\n",
      "üîç Sample of invalid IBANs:\n",
      "                   iban\n",
      "545     BE3773740389328\n",
      "803     BE3406345244590\n",
      "884     BE4063453276789\n",
      "1574  BBE70464520761125\n",
      "1901    BE9293057720614\n",
      "üíæ Updated clean dataset saved to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final.csv\n",
      "üíæ Invalid IBAN rows added to garbage file: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv\n",
      "\n",
      "üìä IBAN Cleaning Summary:\n",
      "‚úÖ Clean dataset shape: (7399, 14)\n",
      "üóëÔ∏è Garbage dataset shape: (7018, 15)\n",
      "üöÄ Ready for ingestion with valid IBANs only!\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Imports\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Load final working dataset\n",
    "file_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final.csv'\n",
    "df = pd.read_csv(file_path, dtype=str)\n",
    "\n",
    "print(\"‚úÖ Dataset loaded. Shape:\", df.shape)\n",
    "\n",
    "# ================================\n",
    "# STEP 1: IBAN Validation Pattern\n",
    "# ================================\n",
    "iban_pattern = r'^BE\\d{14}$'\n",
    "\n",
    "# ================================\n",
    "# STEP 2: Clean IBAN Column\n",
    "# ================================\n",
    "# Strip spaces and upper case\n",
    "df['iban'] = df['iban'].fillna('').str.replace(' ', '').str.upper().str.strip()\n",
    "\n",
    "# ================================\n",
    "# STEP 3: Find Invalid IBANs\n",
    "# ================================\n",
    "invalid_iban_mask = ~df['iban'].str.match(iban_pattern, na=False)\n",
    "\n",
    "invalid_ibans = df.loc[invalid_iban_mask, ['iban']].copy()\n",
    "print(f\"‚ö†Ô∏è Found {len(invalid_ibans)} invalid IBAN(s).\")\n",
    "print(\"üîç Sample of invalid IBANs:\")\n",
    "print(invalid_ibans.head())\n",
    "\n",
    "# ================================\n",
    "# STEP 4: Save Invalid IBANs to Garbage\n",
    "# ================================\n",
    "# Load current garbage data to append invalid IBANs\n",
    "garbage_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv'\n",
    "try:\n",
    "    garbage_df = pd.read_csv(garbage_path, dtype=str)\n",
    "except FileNotFoundError:\n",
    "    garbage_df = pd.DataFrame()  # If no file exists yet\n",
    "\n",
    "# Append only the invalid IBAN rows with full context\n",
    "invalid_iban_full_rows = df.loc[invalid_iban_mask].copy()\n",
    "garbage_df = pd.concat([garbage_df, invalid_iban_full_rows], ignore_index=True)\n",
    "\n",
    "# Drop the invalid IBAN rows from the clean dataset\n",
    "df_clean_final = df.loc[~invalid_iban_mask].copy()\n",
    "\n",
    "# ================================\n",
    "# STEP 5: Save Updated Files\n",
    "# ================================\n",
    "# Save updated clean dataset (OVERWRITE final clean file)\n",
    "df_clean_final.to_csv(file_path, index=False)\n",
    "print(f\"üíæ Updated clean dataset saved to: {file_path}\")\n",
    "\n",
    "# Save updated garbage file\n",
    "garbage_df.to_csv(garbage_path, index=False)\n",
    "print(f\"üíæ Invalid IBAN rows added to garbage file: {garbage_path}\")\n",
    "\n",
    "# ================================\n",
    "# STEP 6: Final Summary\n",
    "# ================================\n",
    "print(\"\\nüìä IBAN Cleaning Summary:\")\n",
    "print(\"‚úÖ Clean dataset shape:\", df_clean_final.shape)\n",
    "print(\"üóëÔ∏è Garbage dataset shape:\", garbage_df.shape)\n",
    "print(\"üöÄ Ready for ingestion with valid IBANs only!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Step 1: Python Fix for Scientific Notation in account_number\n",
    "Here is fully prepared code to fix it in-place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded. Shape: (7399, 11)\n",
      "‚úÖ Scientific notation fixed in 'account_number'.\n",
      "0      1462596514\n",
      "1    860000000000\n",
      "2    737000000000\n",
      "3    733000000000\n",
      "4     63461819055\n",
      "5     63456572365\n",
      "6    310000000000\n",
      "7             NaN\n",
      "8    980000000000\n",
      "9      1119838728\n",
      "Name: account_number, dtype: object\n",
      "üíæ Cleaned data saved back to: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# üîπ Load the dataset from correct file path\n",
    "file_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv'\n",
    "df = pd.read_csv(file_path, dtype=str)  # Read all columns as string to avoid numeric auto-formatting\n",
    "\n",
    "print(\"‚úÖ Dataset loaded. Shape:\", df.shape)\n",
    "\n",
    "# üîπ Function to convert scientific notation to plain number\n",
    "def fix_scientific_notation(value):\n",
    "    try:\n",
    "        if 'E' in str(value).upper():\n",
    "            # Convert to float and format without scientific notation\n",
    "            return '{0:.0f}'.format(float(value))\n",
    "        else:\n",
    "            return value  # Leave as is if not scientific notation\n",
    "    except:\n",
    "        return value  # Leave as is if conversion fails\n",
    "\n",
    "# üîπ Apply function to 'account_number' column\n",
    "df['account_number'] = df['account_number'].apply(fix_scientific_notation)\n",
    "\n",
    "print(\"‚úÖ Scientific notation fixed in 'account_number'.\")\n",
    "print(df['account_number'].head(10))  # Preview for verification\n",
    "\n",
    "# üîπ Save back to same file for Data Wrangler / stakeholder use\n",
    "df.to_csv(file_path, index=False)\n",
    "print(f\"üíæ Cleaned data saved back to: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Optional Refinement (If you want more explicit placeholders):\n",
    "Instead of \"\", you could use clear markers like 'Unknown', '0000', or 'N/A' for better transparency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_fill = {\n",
    "    'last_name': 'Unknown',\n",
    "    'initials': '',\n",
    "    'street_name': 'Unknown',\n",
    "    'house_number': '0',\n",
    "    'postal_code': '0000',\n",
    "    'city': 'Unknown',\n",
    "    'date_of_birth': '',\n",
    "    'account_number': 'Unknown',\n",
    "    'iban': 'Unknown',\n",
    "    'email': ''\n",
    "}\n",
    "df = df.fillna(custom_fill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded. Shape: (7399, 11)\n",
      "\n",
      "üîë Columns and Data Types:\n",
      " last_name         object\n",
      "initials          object\n",
      "street_name       object\n",
      "house_number      object\n",
      "postal_code       object\n",
      "city              object\n",
      "phone_number      object\n",
      "date_of_birth     object\n",
      "account_number    object\n",
      "iban              object\n",
      "email             object\n",
      "dtype: object\n",
      "\n",
      "üìä First 5 records:\n",
      "      last_name initials               street_name house_number postal_code  \\\n",
      "0       Jacobs       C.              Gasmeterlaan          247        9000   \n",
      "1        Dries       K.              Groningenlei           15        2550   \n",
      "2    Vermeulen     KURT            Schongaustraat            7        9100   \n",
      "3     Oirschot       L.            Ertbrandstraat          187        2950   \n",
      "4  Compernolle       R.  Albrecht rodenbachstraat            4        8730   \n",
      "\n",
      "                   city phone_number date_of_birth account_number  \\\n",
      "0                  Gent  475644230.0    24/12/1966     1462596514   \n",
      "1               Kontich   32899040.0           NaN   860000000000   \n",
      "2          Sint-niklaas   32966602.0    13/08/1965   737000000000   \n",
      "3  Kapellen (antwerpen)   36052791.0    25/02/1950   733000000000   \n",
      "4               Beernem   50781034.0           NaN    63461819055   \n",
      "\n",
      "               iban                             email  \n",
      "0  BE94001462596514  christian22christian@hotmail.com  \n",
      "1  BE58860111889579       k_van_den_dries@hotmail.com  \n",
      "2  BE70737015498825         kurt.vermeulen1@skynet.be  \n",
      "3  BE42733156017254             gido.imbert@skynet.be  \n",
      "4  BE31063461819055    rechina.compernolle@telenet.be  \n",
      "\n",
      "üßπ Missing Values per Column:\n",
      " last_name            4\n",
      "initials            46\n",
      "street_name          0\n",
      "house_number        11\n",
      "postal_code         10\n",
      "city                 0\n",
      "phone_number        11\n",
      "date_of_birth     2982\n",
      "account_number     219\n",
      "iban                 0\n",
      "email                7\n",
      "dtype: int64\n",
      "\n",
      "‚úÖ Total Missing Values (should be 0 if fully cleaned): 3290\n",
      "\n",
      "üîç Distinct Counts per Column:\n",
      "last_name: 4663 unique values\n",
      "initials: 1274 unique values\n",
      "street_name: 5068 unique values\n",
      "house_number: 476 unique values\n",
      "postal_code: 562 unique values\n",
      "city: 1656 unique values\n",
      "phone_number: 6677 unique values\n",
      "date_of_birth: 3316 unique values\n",
      "account_number: 2713 unique values\n",
      "iban: 6662 unique values\n",
      "email: 6573 unique values\n",
      "\n",
      "üîé Checking for duplicates on 'iban' and 'account_number'...\n",
      "‚ö†Ô∏è Duplicate IBAN count: 1463\n",
      "‚ö†Ô∏è Duplicate Account Number count: 5103\n",
      "\n",
      "üìä Quick Stats for House Number, Postal Code:\n",
      "       house_number postal_code\n",
      "count          7388        7389\n",
      "unique          476         562\n",
      "top               1        9000\n",
      "freq            204         123\n",
      "\n",
      "üóìÔ∏è Sample of Date of Birth values:\n",
      "0     24/12/1966\n",
      "2     13/08/1965\n",
      "3     25/02/1950\n",
      "5     15/09/1967\n",
      "6     25/07/1968\n",
      "7     26/09/1974\n",
      "10    23/10/1988\n",
      "13    15/11/1963\n",
      "16    15/02/1953\n",
      "17    22/02/1979\n",
      "Name: date_of_birth, dtype: object\n",
      "\n",
      "‚úÖ Example of cleaned rows:\n",
      "     last_name initials            street_name house_number postal_code  \\\n",
      "2473  Van Hoof       M.  Pastoormensaertstraat            9        2340   \n",
      "6731  Naeyaert       T.              Schatting           64        8210   \n",
      "2847  Brangers        M                  Melde           23        2930   \n",
      "169      Theys    BRIAN                Vlierke            5        1820   \n",
      "2036     Herpe    ANNIE       Emiel claeyslaan           31        9050   \n",
      "\n",
      "                city phone_number date_of_birth account_number  \\\n",
      "2473          Beerse   14620720.0    18/06/1963   646000000000   \n",
      "6731        Zedelgem  498812762.0    18/04/1984     1359759841   \n",
      "2847      Brasschaat   36513194.0           NaN     1364792626   \n",
      "169   Steenokkerzeel  477654642.0    28/08/1987   230000000000   \n",
      "2036      Gentbrugge   92313930.0    25/02/1964   737000000000   \n",
      "\n",
      "                  iban                         email  \n",
      "2473  BE92646028839023    nancyberckvens@hotmail.com  \n",
      "6731  BE88001359759841           tnaeyaert@gmail.com  \n",
      "2847  BE59001364792626     marcelabrangers@skynet.be  \n",
      "169   BE76230099238595          briant1712@gmail.com  \n",
      "2036  BE10737446128204  philipe.van.herpe@telenet.be  \n",
      "\n",
      "üöÄ Dataset ready for stakeholder handoff and ingestion!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load final cleaned dataset ===\n",
    "final_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv'\n",
    "df = pd.read_csv(final_path, dtype=str)  # Load as string to avoid formatting issues\n",
    "\n",
    "print(\"‚úÖ Dataset loaded. Shape:\", df.shape)\n",
    "print(\"\\nüîë Columns and Data Types:\\n\", df.dtypes)\n",
    "print(\"\\nüìä First 5 records:\\n\", df.head())\n",
    "\n",
    "# === 1. Check for Missing Values ===\n",
    "missing_summary = df.isnull().sum()\n",
    "print(\"\\nüßπ Missing Values per Column:\\n\", missing_summary)\n",
    "print(\"\\n‚úÖ Total Missing Values (should be 0 if fully cleaned):\", missing_summary.sum())\n",
    "\n",
    "# === 2. Unique & Distinct Values per Column ===\n",
    "print(\"\\nüîç Distinct Counts per Column:\")\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
    "\n",
    "# === 3. Duplicates Check on Key Fields (IBAN, Account Number) ===\n",
    "print(\"\\nüîé Checking for duplicates on 'iban' and 'account_number'...\")\n",
    "duplicate_iban = df[df.duplicated(subset=['iban'], keep=False)]\n",
    "duplicate_account = df[df.duplicated(subset=['account_number'], keep=False)]\n",
    "\n",
    "print(f\"‚ö†Ô∏è Duplicate IBAN count: {len(duplicate_iban)}\")\n",
    "print(f\"‚ö†Ô∏è Duplicate Account Number count: {len(duplicate_account)}\")\n",
    "\n",
    "# Optional: Export duplicates for review\n",
    "duplicate_iban.to_csv(r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\duplicates_iban.csv', index=False)\n",
    "duplicate_account.to_csv(r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\duplicates_account_number.csv', index=False)\n",
    "\n",
    "# === 4. Statistical Overview for Numeric/Important Fields ===\n",
    "print(\"\\nüìä Quick Stats for House Number, Postal Code:\")\n",
    "print(df[['house_number', 'postal_code']].describe())\n",
    "\n",
    "# === 5. Review Date of Birth Formatting ===\n",
    "print(\"\\nüóìÔ∏è Sample of Date of Birth values:\")\n",
    "print(df['date_of_birth'].dropna().head(10))  # Show samples of non-empty\n",
    "\n",
    "# === 6. Example of Cleaned Records for Presentation ===\n",
    "print(\"\\n‚úÖ Example of cleaned rows:\")\n",
    "print(df.sample(5, random_state=42))  # Random clean sample for review\n",
    "\n",
    "print(\"\\nüöÄ Dataset ready for stakeholder handoff and ingestion!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Final cleaned dataset saved successfully at: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv\n",
      "‚úÖ Final Dataset Shape: (6788, 11)\n",
      "\n",
      "üìä Sample of final cleaned data:\n",
      "      last_name initials               street_name house_number postal_code  \\\n",
      "0       Jacobs       C.              Gasmeterlaan          247        9000   \n",
      "1        Dries       K.              Groningenlei           15        2550   \n",
      "2    Vermeulen     KURT            Schongaustraat            7        9100   \n",
      "3     Oirschot       L.            Ertbrandstraat          187        2950   \n",
      "4  Compernolle       R.  Albrecht rodenbachstraat            4        8730   \n",
      "\n",
      "                   city phone_number date_of_birth account_number  \\\n",
      "0                  Gent  475644230.0    24/12/1966     1462596514   \n",
      "1               Kontich   32899040.0                 860000000000   \n",
      "2          Sint-niklaas   32966602.0    13/08/1965   737000000000   \n",
      "3  Kapellen (antwerpen)   36052791.0    25/02/1950   733000000000   \n",
      "4               Beernem   50781034.0                  63461819055   \n",
      "\n",
      "               iban                             email  \n",
      "0  BE94001462596514  christian22christian@hotmail.com  \n",
      "1  BE58860111889579       k_van_den_dries@hotmail.com  \n",
      "2  BE70737015498825         kurt.vermeulen1@skynet.be  \n",
      "3  BE42733156017254             gido.imbert@skynet.be  \n",
      "4  BE31063461819055    rechina.compernolle@telenet.be  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_data(df):\n",
    "    # ‚úÖ Drop duplicate rows across all columns\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # ‚úÖ Replace missing values with blanks for all key fields\n",
    "    df = df.fillna({\n",
    "        'last_name': \"\",\n",
    "        'initials': \"\",\n",
    "        'street_name': \"\",\n",
    "        'house_number': \"\",\n",
    "        'postal_code': \"\",\n",
    "        'city': \"\",\n",
    "        'date_of_birth': \"\",\n",
    "        'account_number': \"\",\n",
    "        'iban': \"\",\n",
    "        'email': \"\"\n",
    "    })\n",
    "\n",
    "    # ‚úÖ Drop rows with missing phone numbers (critical identifier)\n",
    "    df = df.dropna(subset=['phone_number'])\n",
    "\n",
    "    # ‚úÖ Trim leading and trailing whitespace from key text fields\n",
    "    columns_to_trim = ['last_name', 'initials', 'street_name', 'house_number',\n",
    "                       'postal_code', 'city', 'date_of_birth', 'account_number',\n",
    "                       'iban', 'email']\n",
    "    for col in columns_to_trim:\n",
    "        df[col] = df[col].str.strip()\n",
    "\n",
    "    # ‚úÖ Capitalize important text columns for consistency\n",
    "    df['last_name'] = df['last_name'].str.capitalize()\n",
    "    df['street_name'] = df['street_name'].str.capitalize()\n",
    "    df['city'] = df['city'].str.capitalize()\n",
    "\n",
    "    return df\n",
    "\n",
    "# ‚úÖ Load dataset safely (without pyarrow)\n",
    "df = pd.read_csv(r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv', dtype=str)\n",
    "\n",
    "# ‚úÖ Apply cleaning process\n",
    "df_clean = clean_data(df.copy())\n",
    "\n",
    "# ‚úÖ Save cleaned dataset back to same file path (overwrite old version)\n",
    "final_output_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv'\n",
    "df_clean.to_csv(final_output_path, index=False)\n",
    "\n",
    "# ‚úÖ Final confirmations\n",
    "print(f\"üöÄ Final cleaned dataset saved successfully at: {final_output_path}\")\n",
    "print(f\"‚úÖ Final Dataset Shape: {df_clean.shape}\")\n",
    "print(\"\\nüìä Sample of final cleaned data:\\n\", df_clean.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Duplicate IBAN count: 257\n",
      "‚ö†Ô∏è Duplicate Account Number count: 4284\n"
     ]
    }
   ],
   "source": [
    "df_clean.isnull().sum()\n",
    "df_clean.nunique()\n",
    "df_clean.dtypes     \n",
    "\n",
    "# Duplicates in IBAN\n",
    "duplicate_iban = df_clean[df_clean.duplicated('iban', keep=False)]\n",
    "print(f\"‚ö†Ô∏è Duplicate IBAN count: {len(duplicate_iban)}\")\n",
    "\n",
    "# Duplicates in account_number\n",
    "duplicate_account = df_clean[df_clean.duplicated('account_number', keep=False)]\n",
    "print(f\"‚ö†Ô∏è Duplicate Account Number count: {len(duplicate_account)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded. Shape: (6788, 11)\n",
      "‚ö†Ô∏è Duplicate IBANs detected: 132\n",
      "‚ö†Ô∏è Duplicate Account Numbers detected: 4077\n",
      "üóëÔ∏è Total rows to move to garbage file: 4085\n",
      "‚úÖ Final cleaned dataset shape (after removing dups): (2703, 11)\n",
      "üíæ Final clean dataset saved at: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final_review.csv\n",
      "üíæ Garbage data (duplicates) saved at: C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv\n",
      "\n",
      "üìä Cleaning Summary:\n",
      "Original dataset shape: (6788, 11)\n",
      "Duplicates moved to garbage: 4085\n",
      "Final dataset shape: (2703, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Load the current cleaned dataset\n",
    "file_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv'\n",
    "df = pd.read_csv(file_path, dtype=str)\n",
    "print(\"‚úÖ Dataset loaded. Shape:\", df.shape)\n",
    "\n",
    "# =============================\n",
    "# Step 1: Detect Duplicates\n",
    "# =============================\n",
    "\n",
    "# Find duplicate IBAN rows (excluding first occurrence)\n",
    "duplicate_iban = df[df.duplicated('iban', keep='first')]\n",
    "print(f\"‚ö†Ô∏è Duplicate IBANs detected: {len(duplicate_iban)}\")\n",
    "\n",
    "# Find duplicate Account Number rows (excluding first occurrence)\n",
    "duplicate_account = df[df.duplicated('account_number', keep='first')]\n",
    "print(f\"‚ö†Ô∏è Duplicate Account Numbers detected: {len(duplicate_account)}\")\n",
    "\n",
    "# =============================\n",
    "# Step 2: Combine duplicates\n",
    "# =============================\n",
    "# Combine all detected duplicates into one garbage dataset\n",
    "garbage_data = pd.concat([duplicate_iban, duplicate_account]).drop_duplicates()\n",
    "print(f\"üóëÔ∏è Total rows to move to garbage file: {len(garbage_data)}\")\n",
    "\n",
    "# =============================\n",
    "# Step 3: Remove duplicates from clean dataset\n",
    "# =============================\n",
    "# Remove all these duplicates from original dataframe\n",
    "df_clean = df.drop(garbage_data.index).reset_index(drop=True)\n",
    "print(f\"‚úÖ Final cleaned dataset shape (after removing dups): {df_clean.shape}\")\n",
    "\n",
    "# =============================\n",
    "# Step 4: Save cleaned and garbage data\n",
    "# =============================\n",
    "\n",
    "# Save clean dataset back for final review\n",
    "clean_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final_review.csv'\n",
    "df_clean.to_csv(clean_path, index=False)\n",
    "print(f\"üíæ Final clean dataset saved at: {clean_path}\")\n",
    "\n",
    "# Save garbage (duplicates) data\n",
    "garbage_path = r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_garbage_data.csv'\n",
    "garbage_data.to_csv(garbage_path, index=False)\n",
    "print(f\"üíæ Garbage data (duplicates) saved at: {garbage_path}\")\n",
    "\n",
    "# =============================\n",
    "# Step 5: Final Summary\n",
    "# =============================\n",
    "print(\"\\nüìä Cleaning Summary:\")\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Duplicates moved to garbage: {len(garbage_data)}\")\n",
    "print(f\"Final dataset shape: {df_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Final phone number fix applied. Dataset is now fully clean and saved.\n",
      "0    475644230\n",
      "1     32899040\n",
      "2     32966602\n",
      "3     36052791\n",
      "4     50781034\n",
      "5    472453099\n",
      "6    475391350\n",
      "7    476075682\n",
      "8    476385716\n",
      "9    478419735\n",
      "Name: phone_number, dtype: object\n",
      "0    475644230\n",
      "1     32899040\n",
      "2     32966602\n",
      "3     36052791\n",
      "4     50781034\n",
      "5    472453099\n",
      "6    475391350\n",
      "7    476075682\n",
      "8    476385716\n",
      "9    478419735\n",
      "Name: phone_number, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the final cleaned dataset\n",
    "df = pd.read_csv(r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv', dtype=str)\n",
    "\n",
    "# ‚úÖ Fix phone_number by removing '.0' and ensuring it's a string\n",
    "df['phone_number'] = df['phone_number'].astype(str).str.replace(r'\\.0$', '', regex=True)\n",
    "\n",
    "# ‚úÖ Save the fixed dataset back to the same location (overwrite)\n",
    "df.to_csv(r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv', index=False)\n",
    "\n",
    "print(\"üöÄ Final phone number fix applied. Dataset is now fully clean and saved.\")\n",
    "print(df['phone_number'].head(10))  # Quick check\n",
    "# Load the dataset again for verification\n",
    "df = pd.read_csv(r'C:\\Users\\Andre\\OneDrive\\Documents\\Belgium-Bank-Dataset\\output\\belgium_bank_clean_data_final2.csv', dtype=str)\n",
    "\n",
    "# Preview first 10 rows of phone_number to verify fix\n",
    "print(df['phone_number'].head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "belgium_bank_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
